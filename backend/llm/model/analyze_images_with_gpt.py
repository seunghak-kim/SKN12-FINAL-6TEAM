import base64
import os
import openai
from dotenv import load_dotenv
import sys
import json
import numpy as np
from openai import OpenAI
import re
from PIL import Image, ImageOps
import io
from datetime import datetime

sys.path.append(os.path.dirname(__file__))
sys.path.append(os.path.join(os.path.dirname(__file__), '../opensearch_modules'))

from opensearch_client import OpenSearchEmbeddingClient
opensearch_client = OpenSearchEmbeddingClient(host='3.39.30.211')

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

IMAGE_DIR = os.path.join(os.path.dirname(__file__), '../detection_results/images')
RESULT_DIR = os.path.join(os.path.dirname(__file__), '../detection_results/results')

# OpenSearch RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
try:
    # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ opensearch_modulesë¡œ ë³€ê²½í•˜ì—¬ ì„ë² ë”© íŒŒì¼ ì ‘ê·¼
    original_cwd = os.getcwd()
    opensearch_modules_dir = os.path.join(os.path.dirname(__file__), '../opensearch_modules')
    os.chdir(opensearch_modules_dir)
    
    opensearch_client = OpenSearchEmbeddingClient(host='3.39.30.211')
    RAG_INDEX_NAME = "psychology_analysis"
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ ë³µêµ¬
    os.chdir(original_cwd)
    print("OpenSearch RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    print(f"OpenSearch ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    opensearch_client = None
    # ì‘ì—… ë””ë ‰í† ë¦¬ ë³µêµ¬ (ì—ëŸ¬ ë°œìƒ ì‹œì—ë„)
    try:
        os.chdir(original_cwd)
    except:
        pass
def extract_psychological_elements(analysis_text):
    """
    GPT ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œë“¤ì„ ì¶”ì¶œ
    """
    elements = []
    
    # ë‹¤ì–‘í•œ í˜•ì‹ì˜ 1ë‹¨ê³„ ì„¹ì…˜ íŒ¨í„´ ì‹œë„
    patterns = [
        r'## 1\. ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„(.*?)(?=## 2\.|$)',  # ## í˜•ì‹
        r'1\. \*\*ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„\*\*(.*?)(?=2\.|$)',  # ** í˜•ì‹  
        r'### 1\. \*\*ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„\*\*(.*?)(?=### 2\.|$)',  # ### í˜•ì‹
        r'1\. ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„(.*?)(?=2\.|$)'  # ë‹¨ìˆœ í˜•ì‹
    ]
    
    element_section = None
    for pattern in patterns:
        element_section = re.search(pattern, analysis_text, re.DOTALL)
        if element_section:
            break
    
    if element_section:
        element_text = element_section.group(1).strip()
        print(f"ìš”ì†Œ ì„¹ì…˜ ì¶”ì¶œ ì„±ê³µ: {element_text[:100]}...")
        
        # ê° ìš”ì†Œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œ
        lines = element_text.split('\n')
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and len(line) > 5:
                # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±° í›„ ìš”ì†Œ ì¶”ê°€
                clean_element = re.sub(r'^[-â€¢*]\s*', '', line)
                if clean_element:
                    elements.append(clean_element)
    else:
        print("ìš”ì†Œ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„...")
        # ëŒ€ì•ˆ: ì§‘, ë‚˜ë¬´, ì‚¬ëŒ ê´€ë ¨ í‚¤ì›Œë“œ ì§ì ‘ ì¶”ì¶œ
        if 'ì§‘' in analysis_text:
            elements.append('ì§‘')
        if 'ë‚˜ë¬´' in analysis_text:
            elements.append('ë‚˜ë¬´')  
        if 'ì‚¬ëŒ' in analysis_text:
            elements.append('ì‚¬ëŒ')
    
    return elements

def search_rag_documents(query_elements):
    """
    OpenSearchë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ RAG ë¬¸ì„œ ê²€ìƒ‰
    """
    if not opensearch_client or not query_elements:
        return []
    
    try:
        # ëª¨ë“  ìš”ì†Œë¥¼ í•˜ë‚˜ì˜ ì¿¼ë¦¬ë¡œ í•©ì¹¨
        combined_query = ' '.join(query_elements)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
        search_results = opensearch_client.hybrid_search(
            index_name=RAG_INDEX_NAME,
            query_text=combined_query,
            k=10,
            use_reranker=True
        )
        
        # Reranker ê¸°ì¤€ 1ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
        if search_results:
            top_result = search_results[0]
            return {
                'text': top_result['text'],
                'metadata': top_result.get('metadata', {}),
                'document': top_result.get('document', ''),
                'element': top_result.get('element', ''),
                'score': top_result.get('rerank_score', top_result.get('score', 0))
            }  
    except Exception as e:
        print(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    return None

PROMPT = '''
        ë‹¹ì‹ ì€ HTP(House-Tree-Person) ì‹¬ë¦¬ê²€ì‚¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê·¸ë¦¼ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”.
        ë¶„ì„ ë°©ë²•
        1ë‹¨ê³„: ê´€ì°°ëœ íŠ¹ì§•ë“¤
        ê·¸ë¦¼ì—ì„œ ë³´ì´ëŠ” êµ¬ì²´ì ì¸ íŠ¹ì§•ë“¤ì„ ë‚˜ì—´í•´ ì£¼ì„¸ìš”:

        ì§‘: í¬ê¸°, ì°½ë¬¸, ë¬¸, ì§€ë¶•, êµ´ëš ë“±ì˜ íŠ¹ì§•
        ë‚˜ë¬´: í¬ê¸°, ì¤„ê¸°, ê°€ì§€, ì, ë¿Œë¦¬ ë“±ì˜ íŠ¹ì§•
        ì‚¬ëŒ: í¬ê¸°, ìì„¸, ì–¼êµ´, ì˜·ì°¨ë¦¼ ë“±ì˜ íŠ¹ì§•
        ì „ì²´: ë°°ì¹˜, ì„ ì˜ êµµê¸°, ê·¸ë¦¼ ìŠ¤íƒ€ì¼ ë“±

        2ë‹¨ê³„: ì‹¬ë¦¬ì  í•´ì„
        ê° ìš”ì†Œê°€ ë‚˜íƒ€ë‚´ëŠ” ì‹¬ë¦¬ì  ì˜ë¯¸ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”:

        ì§‘ â†’ ê°€ì¡±ê´€ê³„, ì•ˆì •ê°, ì†Œì†ê°
        ë‚˜ë¬´ â†’ ì„±ì¥ìš•êµ¬, ìƒëª…ë ¥, ì ì‘ë ¥
        ì‚¬ëŒ â†’ ìì•„ìƒ, ëŒ€ì¸ê´€ê³„, ì •ì„œìƒíƒœ

        3ë‹¨ê³„: í•µì‹¬ ê°ì • í‚¤ì›Œë“œ
        ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ìš” ê°ì • í‚¤ì›Œë“œë¥¼ 3-5ê°œ ì œì‹œí•´ ì£¼ì„¸ìš”.
        í˜•ì‹: í‚¤ì›Œë“œë§Œ í•œ ì¤„ì”© ë‚˜ì—´ (ì˜ˆ: ë¶ˆì•ˆ, ì•ˆì •ê°, ì†Œì™¸ê°)
        
        ì‘ì„± ê·œì¹™:

        - ëª¨ë“  ë‹µë³€ì€ í•œê¸€ë¡œ '~ì…ë‹ˆë‹¤' ì²´ë¡œ ì‘ì„±
        - ë‹¨ì •ì  í‘œí˜„ë³´ë‹¤ëŠ” '~ë¡œ ë³´ì…ë‹ˆë‹¤', '~í•œ ê²½í–¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤' ë“± ì™„í™”ëœ í‘œí˜„ ì‚¬ìš©
        - ë¶€ì •ì  í•´ì„ê³¼ ê¸ì •ì  í•´ì„ì„ ê· í˜•ìˆê²Œ ì œì‹œ
        - ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•(ë³¼ë“œ, ì´íƒ¤ë¦­ ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ê³  ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ì„±
        - ê°•ì¡°ê°€ í•„ìš”í•œ ê²½ìš° ë”°ì˜´í‘œë‚˜ ê´„í˜¸ë¥¼ ì‚¬ìš©
        - ì´ì œ ì£¼ì–´ì§„ HTP ê·¸ë¦¼ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”.
        '''

openai.api_key = OPENAI_API_KEY

def optimize_image_for_gpt(image_path: str, max_size: tuple = (1024, 1024), quality: int = 85) -> tuple:
    """
    GPT Vision API í˜¸ì¶œì„ ìœ„í•´ ì´ë¯¸ì§€ë¥¼ ìµœì í™”
    
    Args:
        image_path (str): ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
        max_size (tuple): ìµœëŒ€ í¬ê¸° (width, height)
        quality (int): JPEG ì••ì¶• í’ˆì§ˆ (1-100)
        
    Returns:
        tuple: (optimized_base64_string, compression_info)
    """
    try:
        # ì›ë³¸ íŒŒì¼ í¬ê¸° í™•ì¸
        original_size = os.path.getsize(image_path)
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        with Image.open(image_path) as img:
            # EXIF íšŒì „ ì •ë³´ ì ìš©
            img = ImageOps.exif_transpose(img)
            
            # RGBë¡œ ë³€í™˜
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # ì›ë³¸ í¬ê¸° ì €ì¥
            original_dimensions = img.size
            
            # í¬ê¸° ì¡°ì • (ì¢…íš¡ë¹„ ìœ ì§€)
            img.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # ë©”ëª¨ë¦¬ ë²„í¼ì— ì••ì¶•í•˜ì—¬ ì €ì¥
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=quality, optimize=True)
            
            # Base64 ì¸ì½”ë”©
            compressed_bytes = buffer.getvalue()
            compressed_base64 = base64.b64encode(compressed_bytes).decode('utf-8')
            
            # ì••ì¶• ì •ë³´
            compression_info = {
                'original_file_size': original_size,
                'compressed_size': len(compressed_bytes),
                'compression_ratio': round((1 - len(compressed_bytes) / original_size) * 100, 1),
                'original_dimensions': original_dimensions,
                'compressed_dimensions': img.size,
                'base64_length': len(compressed_base64),
                'quality': quality
            }
            
            return compressed_base64, compression_info
            
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°©ì‹ ì‚¬ìš©
        with open(image_path, "rb") as img_file:
            img_bytes = img_file.read()
            return base64.b64encode(img_bytes).decode("utf-8"), {
                'original_file_size': len(img_bytes),
                'compressed_size': len(img_bytes),
                'compression_ratio': 0,
                'error': str(e)
            }

def analyze_image_with_gpt(image_path, prompt, rag_context=None, max_retries=5):
    """
    GPT Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜ (ê±°ë¶€ ë°©ì§€ ë¡œì§ í¬í•¨)
    
    Args:
        image_path (str): ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        prompt (str): GPTì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
        rag_context (dict): RAG ê²€ìƒ‰ ê²°ê³¼ (ì„ íƒì‚¬í•­)
        max_retries (int): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        
    Returns:
        str: GPT ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
    """
    # ê±°ë¶€ ì‘ë‹µ íŒ¨í„´ ì •ì˜
    rejection_patterns = [
        "I'm unable to",
        "I can't provide an analysis",
        "I'm sorry",
        "ì£„ì†¡í•©ë‹ˆë‹¤",
        "ì£„ì†¡í•˜ì§€ë§Œ",
        "ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "ë¶„ì„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤",
        "ì •í™•í•˜ê²Œ ë¶„ì„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤",
        "ì¸ì‹ì„ í•˜ê¸° êµ‰ì¥íˆ ì–´ë µìŠµë‹ˆë‹¤",
        "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤",
        "ì¶”ê°€ ì •ë³´ë‚˜ ì„¤ëª…ì„ ì œê³µí•´ ì£¼ì‹œë©´",
        "í•˜ì§€ë§Œ ì¼ë°˜ì ì¸",
        "ì˜ˆë¥¼ ë“¤ì–´ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
        "ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    ]
    
    for attempt in range(max_retries):
        try:
            # ì¬ì‹œë„ ì‹œ í”„ë¡¬í”„íŠ¸ ê°•í™”
            if attempt > 0:
                enhanced_prompt = f"""
{prompt}

[ì¤‘ìš”] ì´ì „ ì‹œë„ì—ì„œ ì´ë¯¸ì§€ ë¶„ì„ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. 
ì´ë²ˆì—ëŠ” ë°˜ë“œì‹œ ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìš”ì†Œë“¤ì„ ê´€ì°°í•˜ì—¬ HTP ì‹¬ë¦¬ê²€ì‚¬ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.
ì´ë¯¸ì§€ê°€ íë¦¬ê±°ë‚˜ ë¶ˆë¶„ëª…í•˜ë”ë¼ë„ ë³´ì´ëŠ” ìš”ì†Œë“¤(ì„ , ëª¨ì–‘, í¬ê¸°, ìœ„ì¹˜ ë“±)ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
ì™„ì „í•œ ê±°ë¶€ë³´ë‹¤ëŠ” ê´€ì°° ê°€ëŠ¥í•œ ìš”ì†Œë¼ë„ ë¶„ì„í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.
"""
            else:
                enhanced_prompt = prompt

            # ğŸš€ ì´ë¯¸ì§€ ìµœì í™”: ì´ë¯¸ YOLOì—ì„œ 320x320ìœ¼ë¡œ ì••ì¶•ëœ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
            try:
                import os
                from PIL import Image
                
                # íŒŒì¼ í¬ê¸°ì™€ ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
                file_size = os.path.getsize(image_path)
                with Image.open(image_path) as img:
                    img_size = img.size
                
                # ì´ë¯¸ ì‘ì€ ì´ë¯¸ì§€(YOLO ì²˜ë¦¬ëœ)ì´ë©´ ì¶”ê°€ ì••ì¶• ì—†ì´ ì‚¬ìš©
                if img_size[0] <= 320 and img_size[1] <= 320 and file_size < 50000:  # 50KB ë¯¸ë§Œ
                    print(f"ğŸ“¸ ì´ë¯¸ ìµœì í™”ëœ ì´ë¯¸ì§€ ê°ì§€: {img_size}, {file_size:,} bytes - ì¶”ê°€ ì••ì¶• ìƒëµ")
                    with open(image_path, 'rb') as f:
                        img_base64 = base64.b64encode(f.read()).decode('utf-8')
                    compression_info = {
                        'original_file_size': file_size,
                        'compressed_size': file_size,
                        'compression_ratio': 0,
                        'original_dimensions': img_size,
                        'compressed_dimensions': img_size
                    }
                else:
                    print(f"ğŸ“¸ í° ì´ë¯¸ì§€ ê°ì§€: {img_size}, {file_size:,} bytes - GPTìš© ì••ì¶• ì ìš©")
                    img_base64, compression_info = optimize_image_for_gpt(image_path, max_size=(1024, 1024), quality=85)
                    
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ ì‹¤íŒ¨, ê¸°ë³¸ ì••ì¶• ì ìš©: {e}")
                img_base64, compression_info = optimize_image_for_gpt(image_path, max_size=(1024, 1024), quality=85)
            
            # ì••ì¶• ê²°ê³¼ ë¡œê·¸
            print(f"ì´ë¯¸ì§€ íŒŒì¼ í¬ê¸°: {compression_info['original_file_size']:,} bytes")
            if 'error' not in compression_info:
                print(f"ì²˜ë¦¬ í›„ í¬ê¸°: {compression_info['compressed_size']:,} bytes")
                print(f"ì••ì¶•ë¥ : {compression_info['compression_ratio']}%")
                print(f"ì›ë³¸ í¬ê¸°: {compression_info['original_dimensions']}")
                print(f"ì²˜ë¦¬ í›„ í¬ê¸°: {compression_info['compressed_dimensions']}")
            
            data_url = f"data:image/jpeg;base64,{img_base64}"
            print(f"MIME íƒ€ì…: image/jpeg")
            print(f"Base64 ê¸¸ì´: {len(img_base64)}")
            
            # ë©”ì‹œì§€ ì»¨í…ì¸  êµ¬ì„±
            content = [
                {"type": "text", "text": enhanced_prompt},
                {"type": "image_url", "image_url": {"url": data_url}}
            ]
            
            # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if rag_context:
                rag_text = f"\n\n[ì°¸ê³  ìë£Œ]\në¬¸ì„œ: {rag_context['document']} - {rag_context['element']}\në‚´ìš©: {rag_context['text']}"
                content.append({"type": "text", "text": rag_text})

            import time
            gpt_start_time = time.time()
            gpt_start_datetime = datetime.now()
            print(f"ğŸ¤– [TIMING] GPT API í˜¸ì¶œ ì‹œì‘: {gpt_start_datetime.strftime('%H:%M:%S.%f')[:-3]} (ì‹œë„ {attempt + 1}/{max_retries})")
            
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ HTP(House-Tree-Person) ì‹¬ë¦¬ê²€ì‚¬ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ê·¸ë¦¼ì€ ì‹¬ë¦¬ê²€ì‚¬ ëª©ì ìœ¼ë¡œ ê·¸ë ¤ì§„ ê·¸ë¦¼ì´ë©°, ì‹¤ì œ ì¸ë¬¼ì˜ ì‹ ì› ì‹ë³„ì´ ì•„ë‹Œ ì‹¬ë¦¬ì  íŠ¹ì„± ë¶„ì„ì„ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤. ê·¸ë¦¼ì˜ ì‹œê°ì  ìš”ì†Œë“¤ì„ í†µí•´ ì‹¬ë¦¬ ìƒíƒœë¥¼ ë¶„ì„í•´ ì£¼ì„¸ìš”. ê°œì¸ì˜ ì •ì²´ì„±ì´ë‚˜ ì‹ ì›ì„ íŒŒì•…í•˜ë ¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ê·¸ë¦¼ í‘œí˜„ ë°©ì‹ì„ í†µí•œ ì‹¬ë¦¬ ë¶„ì„ì„ì„ ëª…ì‹¬í•˜ì„¸ìš”. ì´ë¯¸ì§€ê°€ ì œëŒ€ë¡œ ë³´ì´ì§€ ì•Šìœ¼ë©´ 'ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ì‘ë‹µí•˜ì§€ ë§ê³ , ë‹¤ì‹œ ì‹œë„í•´ë³´ê±°ë‚˜ ì´ë¯¸ì§€ íŒŒì¼ ë¬¸ì œì¼ ìˆ˜ ìˆë‹¤ê³  ì•ˆë‚´í•´ì£¼ì„¸ìš”."},
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                max_tokens=2000,
            )
            
            gpt_end_time = time.time()
            gpt_duration = gpt_end_time - gpt_start_time
            gpt_end_datetime = datetime.now()
            print(f"âœ… [TIMING] GPT API í˜¸ì¶œ ì™„ë£Œ: {gpt_end_datetime.strftime('%H:%M:%S.%f')[:-3]}")
            print(f"â±ï¸  [TIMING] GPT API ì†Œìš”ì‹œê°„: {gpt_duration:.2f}ì´ˆ")
            
            result_text = response.choices[0].message.content.strip()
            
            # ê±°ë¶€ ì‘ë‹µ íŒ¨í„´ í™•ì¸
            is_rejection = False
            for pattern in rejection_patterns:
                if pattern.lower() in result_text.lower():
                    is_rejection = True
                    print(f"ê±°ë¶€ ì‘ë‹µ íŒ¨í„´ ê°ì§€: '{pattern}' (ì‹œë„ {attempt + 1}/{max_retries})")
                    break
            
            # ê±°ë¶€ ì‘ë‹µì´ ì•„ë‹ˆê±°ë‚˜ ë§ˆì§€ë§‰ ì‹œë„ë¼ë©´ ê²°ê³¼ ë°˜í™˜
            if not is_rejection or attempt == max_retries - 1:
                if is_rejection and attempt == max_retries - 1:
                    print(f"ê²½ê³ : ëª¨ë“  ì¬ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return result_text
            
            # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
            print(f"ê±°ë¶€ ì‘ë‹µìœ¼ë¡œ ì¸í•œ ì¬ì‹œë„ ëŒ€ê¸° ì¤‘... (2ì´ˆ)")
            time.sleep(2)
            
        except Exception as e:
            print(f"GPT API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                raise
            # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
            import time
            time.sleep(2)
    
    return "ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


def analyze_image_gpt(image_base):
    """GPTì™€ OpenSearch RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        image_base (str): ë¶„ì„í•  ì´ë¯¸ì§€ì˜ ê¸°ë³¸ íŒŒì¼ëª… (ì˜ˆ: test4)
        
    Returns:
        dict: ë¶„ì„ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    if not OPENAI_API_KEY:
        print("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        print(f"í˜„ì¬ OPENAI_API_KEY ê°’: {OPENAI_API_KEY[:10] if OPENAI_API_KEY else 'None'}...")
        return None

    print(f"IMAGE_DIR ê²½ë¡œ: {IMAGE_DIR}")
    if not os.path.exists(IMAGE_DIR):
        print(f"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {IMAGE_DIR}")
        print(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
        return None

    target_filename = f"detection_result_{image_base}.jpg"
    image_path = os.path.join(IMAGE_DIR, target_filename)
    print(f"ì°¾ëŠ” ì´ë¯¸ì§€ íŒŒì¼: {image_path}")
    if not os.path.exists(image_path):
        print(f"{IMAGE_DIR} í´ë”ì— {target_filename} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        # í´ë” ë‚´ íŒŒì¼ ëª©ë¡ ì¶œë ¥
        try:
            files = os.listdir(IMAGE_DIR)
            print(f"í´ë” ë‚´ íŒŒì¼ ëª©ë¡: {files}")
        except Exception as e:
            print(f"í´ë” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

    print(f"\n===== {target_filename} ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ =====")
    
    # ë¶„ì„ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    import time
    analysis_start_time = time.time()
    analysis_start_datetime = datetime.now()
    print(f"ğŸš€ [TIMING] ì‹¬ë¦¬ ë¶„ì„ ì „ì²´ ì‹œì‘: {analysis_start_datetime.strftime('%H:%M:%S.%f')[:-3]}")
    
    try:
        # 1ì°¨ GPT í•´ì„ (ì´ˆê¸° ë¶„ì„)
        print("1ë‹¨ê³„: ì´ˆê¸° ì‹¬ë¦¬ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        initial_analysis = analyze_image_with_gpt(image_path, PROMPT)
        print("\n[ì´ˆê¸° ë¶„ì„ ê²°ê³¼]")
        print(initial_analysis)
        
        # ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì¶”ì¶œ
        print("\n2ë‹¨ê³„: ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì¶”ì¶œ ì¤‘...")
        psychological_elements = extract_psychological_elements(initial_analysis)
        print(f"ì¶”ì¶œëœ ìš”ì†Œë“¤: {psychological_elements}")
        
        # OpenSearch RAG ê²€ìƒ‰
        print("\n3ë‹¨ê³„: RAG ì‹œìŠ¤í…œì„ í†µí•œ ê´€ë ¨ ìë£Œ ê²€ìƒ‰ ì¤‘...")
        rag_result = search_rag_documents(psychological_elements)
        
        if rag_result:
            print(f"ê²€ìƒ‰ëœ ê´€ë ¨ ìë£Œ: {rag_result['document']} - {rag_result['element']}")
            print(f"ê´€ë ¨ë„ ì ìˆ˜: {rag_result['score']:.4f}")
            
            # RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ìµœì¢… ë¶„ì„
            print("\n4ë‹¨ê³„: RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ìµœì¢… ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
            final_prompt = f"""
                            ì•„ë˜ëŠ” ì‹¬ë¦¬ ê·¸ë¦¼ ê²€ì‚¬ì˜ ì´ˆê¸° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

                            {initial_analysis}

                            ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì œê³µëœ ì°¸ê³  ìë£Œë¥¼ í™œìš©í•˜ì—¬ ë”ìš± ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ìµœì¢… ì‹¬ë¦¬ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.
                            íŠ¹íˆ ì°¸ê³  ìë£Œì˜ ì „ë¬¸ì  í•´ì„ì„ ë°˜ì˜í•˜ì—¬ ë¶„ì„ì˜ ê¹Šì´ë¥¼ ë”í•´ì£¼ì„¸ìš”.
                            ë°˜ë“œì‹œ ~ì…ë‹ˆë‹¤ ì²´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
                            """
            result_text_gpt = analyze_image_with_gpt(image_path, final_prompt, rag_result)
        else:
            print("ê´€ë ¨ RAG ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì´ˆê¸° ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            result_text_gpt = initial_analysis
        
        print("\n[ìµœì¢… ë¶„ì„ ê²°ê³¼]")
        print(result_text_gpt)
        
    except Exception as e:
        # ì˜¤ë¥˜ ì‹œê°„ ê¸°ë¡
        error_time = time.time()
        error_duration = error_time - analysis_start_time if 'analysis_start_time' in locals() else 0
        error_datetime = datetime.now()
        print(f"âŒ [TIMING] ì‹¬ë¦¬ ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ: {error_datetime.strftime('%H:%M:%S.%f')[:-3]}")
        if error_duration > 0:
            print(f"â±ï¸  [TIMING] ì˜¤ë¥˜ê¹Œì§€ ì†Œìš”ì‹œê°„: {error_duration:.2f}ì´ˆ ({error_duration/60:.1f}ë¶„)")
        
        print(f"ë¶„ì„ ì‹¤íŒ¨ - ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
        print(f"ì˜¤ë¥˜ íƒ€ì…: {type(e)}")
        import traceback
        print("ì „ì²´ ì˜¤ë¥˜ ì¶”ì :")
        traceback.print_exc()
        return None

    # ìš”ì•½ í•´ì„ë¬¸ ìƒì„±
    print("\n5ë‹¨ê³„: ìš”ì•½ í•´ì„ë¬¸ ìƒì„± ì¤‘...")
    SUMMARY_PROMPT = f"""
        ì•„ë˜ì˜ ê·¸ë¦¼ ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬,
        ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì „ì²´ì ì¸ ì‹¬ë¦¬ ìƒíƒœì™€ íŠ¹ì§•ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½Â·ì •ë¦¬í•´ì£¼ëŠ” í•´ì„ë¬¸ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        ë°˜ë“œì‹œ ~ì…ë‹ˆë‹¤ ì²´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

        ë¶„ì„ ê²°ê³¼:
        {result_text_gpt}
        """
    try:
        result_text = analyze_image_with_gpt(image_path, SUMMARY_PROMPT)
    except Exception as e:
        print(f"ìš”ì•½ í•´ì„ë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
        result_text = "(ìš”ì•½ í•´ì„ë¬¸ ìƒì„± ì‹¤íŒ¨)"

    # ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
    enriched = []
    if rag_result:
        enriched.append({
            'element': rag_result['element'],
            'condition': rag_result['text'][:100] + '...' if len(rag_result['text']) > 100 else rag_result['text'],
            'keywords': rag_result['metadata'].get('keywords', [])
        })

    # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„± (íŒŒì¼ ì €ì¥ ì—†ì´)
    result = {
        "raw_text": result_text_gpt,
        "result_text": result_text,
        "items": enriched,
        "rag_context": rag_result
    }
    
    # ë¶„ì„ ì™„ë£Œ ì‹œê°„ ê¸°ë¡
    analysis_end_time = time.time()
    analysis_duration = analysis_end_time - analysis_start_time
    analysis_end_datetime = datetime.now()
    print(f"âœ… [TIMING] ì‹¬ë¦¬ ë¶„ì„ ì „ì²´ ì™„ë£Œ: {analysis_end_datetime.strftime('%H:%M:%S.%f')[:-3]}")
    print(f"â±ï¸  [TIMING] ì‹¬ë¦¬ ë¶„ì„ ì´ ì†Œìš”ì‹œê°„: {analysis_duration:.2f}ì´ˆ ({analysis_duration/60:.1f}ë¶„)")
    
    return result

def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì ì²˜ë¦¬"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ë¶„ì„í•  detection_result_*.jpg íŒŒì¼ëª…ì„ ì§€ì •í•˜ì„¸ìš”.")
    parser.add_argument('--image', type=str, required=True, help='ë¶„ì„í•  detection_result_*.jpg íŒŒì¼ëª… (ì˜ˆ: detection_result_test4.jpg)')
    args = parser.parse_args()

    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±° (test4.jpg â†’ test4, test4 â†’ test4)
    image_base = os.path.splitext(args.image)[0]
    
    # ìƒˆë¡œìš´ ëª¨ë“ˆí™”ëœ í•¨ìˆ˜ í˜¸ì¶œ
    result = analyze_image_gpt(image_base)
    
    if result is None:
        print("ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    print("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 
import base64
print("DEBUG: analyze_images_with_gpt.py imported")
import os
import openai
from dotenv import load_dotenv
import sys
import json
import numpy as np
from openai import OpenAI
import re
from PIL import Image, ImageOps
import io
from datetime import datetime

load_dotenv()

sys.path.append(os.path.dirname(__file__))
sys.path.append(os.path.join(os.path.dirname(__file__), '../opensearch_modules'))

from opensearch_client import OpenSearchEmbeddingClient
opensearch_client = OpenSearchEmbeddingClient(host=os.getenv('OPENSEARCH_HOST', 'opensearch-node'))

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

IMAGE_DIR = os.path.join(os.path.dirname(__file__), '../detection_results/images')
RESULT_DIR = os.path.join(os.path.dirname(__file__), '../detection_results/results')

# OpenSearch RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
try:
    # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ opensearch_modulesë¡œ ë³€ê²½í•˜ì—¬ ì„ë² ë”© íŒŒì¼ ì ‘ê·¼
    original_cwd = os.getcwd()
    opensearch_modules_dir = os.path.join(os.path.dirname(__file__), '../opensearch_modules')
    os.chdir(opensearch_modules_dir)
    
    opensearch_client = OpenSearchEmbeddingClient(host=os.getenv('OPENSEARCH_HOST', 'opensearch-node'))
    RAG_INDEX_NAME = "psychology_analysis"
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ ë³µêµ¬
    os.chdir(original_cwd)
    print("OpenSearch RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    print(f"OpenSearch ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    opensearch_client = None
    # ì‘ì—… ë””ë ‰í† ë¦¬ ë³µêµ¬ (ì—ëŸ¬ ë°œìƒ ì‹œì—ë„)
    try:
        os.chdir(original_cwd)
    except:
        pass
def extract_psychological_elements(analysis_text):
    """
    GPT ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œë“¤ì„ ì¶”ì¶œ
    """
    elements = []
    
    # ë‹¤ì–‘í•œ í˜•ì‹ì˜ 1ë‹¨ê³„ ì„¹ì…˜ íŒ¨í„´ ì‹œë„
    patterns = [
        r'## 1\. ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„(.*?)(?=## 2\.|$)',  # ## í˜•ì‹
        r'1\. \*\*ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„\*\*(.*?)(?=2\.|$)',  # ** í˜•ì‹  
        r'### 1\. \*\*ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„\*\*(.*?)(?=### 2\.|$)',  # ### í˜•ì‹
        r'1\. ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„(.*?)(?=2\.|$)'  # ë‹¨ìˆœ í˜•ì‹
    ]
    
    element_section = None
    for pattern in patterns:
        element_section = re.search(pattern, analysis_text, re.DOTALL)
        if element_section:
            break
    
    if element_section:
        element_text = element_section.group(1).strip()
        print(f"ìš”ì†Œ ì„¹ì…˜ ì¶”ì¶œ ì„±ê³µ: {element_text[:100]}...")
        
        # ê° ìš”ì†Œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œ
        lines = element_text.split('\n')
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and len(line) > 5:
                # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±° í›„ ìš”ì†Œ ì¶”ê°€
                clean_element = re.sub(r'^[-â€¢*]\s*', '', line)
                if clean_element:
                    elements.append(clean_element)
    else:
        print("ìš”ì†Œ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„...")
        # ëŒ€ì•ˆ: ì§‘, ë‚˜ë¬´, ì‚¬ëŒ ê´€ë ¨ í‚¤ì›Œë“œ ì§ì ‘ ì¶”ì¶œ
        if 'ì§‘' in analysis_text:
            elements.append('ì§‘')
        if 'ë‚˜ë¬´' in analysis_text:
            elements.append('ë‚˜ë¬´')  
        if 'ì‚¬ëŒ' in analysis_text:
            elements.append('ì‚¬ëŒ')
    
    return elements

def search_rag_documents(query_elements):
    """
    OpenSearchë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ RAG ë¬¸ì„œ ê²€ìƒ‰
    """
    if not opensearch_client or not query_elements:
        return []
    
    try:
        # ëª¨ë“  ìš”ì†Œë¥¼ í•˜ë‚˜ì˜ ì¿¼ë¦¬ë¡œ í•©ì¹¨
        combined_query = ' '.join(query_elements)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
        search_results = opensearch_client.hybrid_search(
            index_name=RAG_INDEX_NAME,
            query_text=combined_query,
            k=10,
            use_reranker=True
        )
        
        # Reranker ê¸°ì¤€ 1ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
        if search_results:
            top_result = search_results[0]
            return {
                'text': top_result['text'],
                'metadata': top_result.get('metadata', {}),
                'document': top_result.get('document', ''),
                'element': top_result.get('element', ''),
                'score': top_result.get('rerank_score', top_result.get('score', 0))
            }  
    except Exception as e:
        print(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    return None

PROMPT = '''
        ë‹¹ì‹ ì€ HTP(House-Tree-Person) ì‹¬ë¦¬ê²€ì‚¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê·¸ë¦¼ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.
        
        {
            "features": {
                "house": ["ì§‘ì˜ íŠ¹ì§•1", "ì§‘ì˜ íŠ¹ì§•2"],
                "tree": ["ë‚˜ë¬´ì˜ íŠ¹ì§•1", "ë‚˜ë¬´ì˜ íŠ¹ì§•2"],
                "person": ["ì‚¬ëŒì˜ íŠ¹ì§•1", "ì‚¬ëŒì˜ íŠ¹ì§•2"],
                "overall": ["ì „ì²´ì ì¸ íŠ¹ì§•1", "ì „ì²´ì ì¸ íŠ¹ì§•2"]
            },
            "psychological_analysis": {
                "house": "ì§‘ì— ëŒ€í•œ ì‹¬ë¦¬ì  í•´ì„",
                "tree": "ë‚˜ë¬´ì— ëŒ€í•œ ì‹¬ë¦¬ì  í•´ì„",
                "person": "ì‚¬ëŒì— ëŒ€í•œ ì‹¬ë¦¬ì  í•´ì„"
            },
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", "í‚¤ì›Œë“œ4", "í‚¤ì›Œë“œ5"],
            "summary": "ì „ì²´ì ì¸ ì‹¬ë¦¬ ìƒíƒœ ìš”ì•½ (3-4ë¬¸ì¥)"
        }

        ì‘ì„± ê·œì¹™:
        - ëª¨ë“  ê°’ì€ í•œê¸€ë¡œ ì‘ì„±
        - ë‹¨ì •ì  í‘œí˜„ë³´ë‹¤ëŠ” '~ë¡œ ë³´ì…ë‹ˆë‹¤', '~í•œ ê²½í–¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤' ë“± ì™„í™”ëœ í‘œí˜„ ì‚¬ìš©
        - ë¶€ì •ì  í•´ì„ê³¼ ê¸ì •ì  í•´ì„ì„ ê· í˜•ìˆê²Œ ì œì‹œ
        - JSON í˜•ì‹ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•  ê²ƒ
        '''

openai.api_key = OPENAI_API_KEY

def optimize_image_for_gpt(image_path: str, max_size: tuple = (1024, 1024), quality: int = 85) -> tuple:
    """
    GPT Vision API í˜¸ì¶œì„ ìœ„í•´ ì´ë¯¸ì§€ë¥¼ ìµœì í™”
    
    Args:
        image_path (str): ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
        max_size (tuple): ìµœëŒ€ í¬ê¸° (width, height)
        quality (int): JPEG ì••ì¶• í’ˆì§ˆ (1-100)
        
    Returns:
        tuple: (optimized_base64_string, compression_info)
    """
    try:
        # ì›ë³¸ íŒŒì¼ í¬ê¸° í™•ì¸
        original_size = os.path.getsize(image_path)
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        with Image.open(image_path) as img:
            # EXIF íšŒì „ ì •ë³´ ì ìš©
            img = ImageOps.exif_transpose(img)
            
            # RGBë¡œ ë³€í™˜
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # ì›ë³¸ í¬ê¸° ì €ì¥
            original_dimensions = img.size
            
            # í¬ê¸° ì¡°ì • (ì¢…íš¡ë¹„ ìœ ì§€)
            img.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # ë©”ëª¨ë¦¬ ë²„í¼ì— ì••ì¶•í•˜ì—¬ ì €ì¥
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=quality, optimize=True)
            
            # Base64 ì¸ì½”ë”©
            compressed_bytes = buffer.getvalue()
            compressed_base64 = base64.b64encode(compressed_bytes).decode('utf-8')
            
            # ì••ì¶• ì •ë³´
            compression_info = {
                'original_file_size': original_size,
                'compressed_size': len(compressed_bytes),
                'compression_ratio': round((1 - len(compressed_bytes) / original_size) * 100, 1),
                'original_dimensions': original_dimensions,
                'compressed_dimensions': img.size,
                'base64_length': len(compressed_base64),
                'quality': quality
            }
            
            return compressed_base64, compression_info
            
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°©ì‹ ì‚¬ìš©
        with open(image_path, "rb") as img_file:
            img_bytes = img_file.read()
            return base64.b64encode(img_bytes).decode("utf-8"), {
                'original_file_size': len(img_bytes),
                'compressed_size': len(img_bytes),
                'compression_ratio': 0,
                'error': str(e)
            }

def analyze_image_with_gpt(image_path, prompt, rag_context=None, max_retries=5):
    """
    GPT Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜ (ê±°ë¶€ ë°©ì§€ ë¡œì§ í¬í•¨)
    
    Args:
        image_path (str): ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        prompt (str): GPTì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
        rag_context (dict): RAG ê²€ìƒ‰ ê²°ê³¼ (ì„ íƒì‚¬í•­)
        max_retries (int): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        
    Returns:
        str: GPT ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
    """
    # ê±°ë¶€ ì‘ë‹µ íŒ¨í„´ ì •ì˜
    rejection_patterns = [
        "I'm unable to",
        "I can't provide an analysis",
        "I'm sorry",
        "ì£„ì†¡í•©ë‹ˆë‹¤",
        "ì£„ì†¡í•˜ì§€ë§Œ",
        "ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "ë¶„ì„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤",
        "ì •í™•í•˜ê²Œ ë¶„ì„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤",
        "ì¸ì‹ì„ í•˜ê¸° êµ‰ì¥íˆ ì–´ë µìŠµë‹ˆë‹¤",
        "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤",
        "ì¶”ê°€ ì •ë³´ë‚˜ ì„¤ëª…ì„ ì œê³µí•´ ì£¼ì‹œë©´",
        "í•˜ì§€ë§Œ ì¼ë°˜ì ì¸",
        "ì˜ˆë¥¼ ë“¤ì–´ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
        "ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    ]
    
    for attempt in range(max_retries):
        try:
            # ì¬ì‹œë„ ì‹œ í”„ë¡¬í”„íŠ¸ ê°•í™”
            if attempt > 0:
                enhanced_prompt = f"""
{prompt}

[ì¤‘ìš”] ì´ì „ ì‹œë„ì—ì„œ ì´ë¯¸ì§€ ë¶„ì„ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. 
ì´ë²ˆì—ëŠ” ë°˜ë“œì‹œ ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìš”ì†Œë“¤ì„ ê´€ì°°í•˜ì—¬ HTP ì‹¬ë¦¬ê²€ì‚¬ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.
ì´ë¯¸ì§€ê°€ íë¦¬ê±°ë‚˜ ë¶ˆë¶„ëª…í•˜ë”ë¼ë„ ë³´ì´ëŠ” ìš”ì†Œë“¤(ì„ , ëª¨ì–‘, í¬ê¸°, ìœ„ì¹˜ ë“±)ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
ì™„ì „í•œ ê±°ë¶€ë³´ë‹¤ëŠ” ê´€ì°° ê°€ëŠ¥í•œ ìš”ì†Œë¼ë„ ë¶„ì„í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.
"""
            else:
                enhanced_prompt = prompt

            # ğŸš€ ì´ë¯¸ì§€ ìµœì í™”: ì´ë¯¸ YOLOì—ì„œ 320x320ìœ¼ë¡œ ì••ì¶•ëœ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
            try:
                import os
                from PIL import Image
                
                # íŒŒì¼ í¬ê¸°ì™€ ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
                file_size = os.path.getsize(image_path)
                with Image.open(image_path) as img:
                    img_size = img.size
                
                # ì´ë¯¸ ì‘ì€ ì´ë¯¸ì§€(YOLO ì²˜ë¦¬ëœ)ì´ë©´ ì¶”ê°€ ì••ì¶• ì—†ì´ ì‚¬ìš©
                if img_size[0] <= 320 and img_size[1] <= 320 and file_size < 50000:  # 50KB ë¯¸ë§Œ
                    print(f"ğŸ“¸ ì´ë¯¸ ìµœì í™”ëœ ì´ë¯¸ì§€ ê°ì§€: {img_size}, {file_size:,} bytes - ì¶”ê°€ ì••ì¶• ìƒëµ")
                    with open(image_path, 'rb') as f:
                        img_base64 = base64.b64encode(f.read()).decode('utf-8')
                    compression_info = {
                        'original_file_size': file_size,
                        'compressed_size': file_size,
                        'compression_ratio': 0,
                        'original_dimensions': img_size,
                        'compressed_dimensions': img_size
                    }
                else:
                    print(f"ğŸ“¸ í° ì´ë¯¸ì§€ ê°ì§€: {img_size}, {file_size:,} bytes - GPTìš© ì••ì¶• ì ìš©")
                    img_base64, compression_info = optimize_image_for_gpt(image_path, max_size=(1024, 1024), quality=85)
                    
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ ì‹¤íŒ¨, ê¸°ë³¸ ì••ì¶• ì ìš©: {e}")
                img_base64, compression_info = optimize_image_for_gpt(image_path, max_size=(1024, 1024), quality=85)
            
            # ì••ì¶• ê²°ê³¼ ë¡œê·¸
            print(f"ì´ë¯¸ì§€ íŒŒì¼ í¬ê¸°: {compression_info['original_file_size']:,} bytes")
            if 'error' not in compression_info:
                print(f"ì²˜ë¦¬ í›„ í¬ê¸°: {compression_info['compressed_size']:,} bytes")
                print(f"ì••ì¶•ë¥ : {compression_info['compression_ratio']}%")
                print(f"ì›ë³¸ í¬ê¸°: {compression_info['original_dimensions']}")
                print(f"ì²˜ë¦¬ í›„ í¬ê¸°: {compression_info['compressed_dimensions']}")
            
            data_url = f"data:image/jpeg;base64,{img_base64}"
            print(f"MIME íƒ€ì…: image/jpeg")
            print(f"Base64 ê¸¸ì´: {len(img_base64)}")
            
            # ë©”ì‹œì§€ ì»¨í…ì¸  êµ¬ì„±
            content = [
                {"type": "text", "text": enhanced_prompt},
                {"type": "image_url", "image_url": {"url": data_url}}
            ]
            
            # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if rag_context:
                rag_text = f"\n\n[ì°¸ê³  ìë£Œ]\në¬¸ì„œ: {rag_context['document']} - {rag_context['element']}\në‚´ìš©: {rag_context['text']}"
                content.append({"type": "text", "text": rag_text})

            import time
            gpt_start_time = time.time()
            gpt_start_datetime = datetime.now()
            print(f"ğŸ¤– [TIMING] GPT API í˜¸ì¶œ ì‹œì‘: {gpt_start_datetime.strftime('%H:%M:%S.%f')[:-3]} (ì‹œë„ {attempt + 1}/{max_retries})")
            
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ HTP(House-Tree-Person) ì‹¬ë¦¬ê²€ì‚¬ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ ì£¼ì„¸ìš”."},
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                max_tokens=2000,
                response_format={"type": "json_object"}
            )
            
            gpt_end_time = time.time()
            gpt_duration = gpt_end_time - gpt_start_time
            gpt_end_datetime = datetime.now()
            print(f"âœ… [TIMING] GPT API í˜¸ì¶œ ì™„ë£Œ: {gpt_end_datetime.strftime('%H:%M:%S.%f')[:-3]}")
            print(f"â±ï¸  [TIMING] GPT API ì†Œìš”ì‹œê°„: {gpt_duration:.2f}ì´ˆ")
            
            result_text = response.choices[0].message.content.strip()
            
            # ê±°ë¶€ ì‘ë‹µ íŒ¨í„´ í™•ì¸
            is_rejection = False
            for pattern in rejection_patterns:
                if pattern.lower() in result_text.lower():
                    is_rejection = True
                    print(f"ê±°ë¶€ ì‘ë‹µ íŒ¨í„´ ê°ì§€: '{pattern}' (ì‹œë„ {attempt + 1}/{max_retries})")
                    break
            
            # ê±°ë¶€ ì‘ë‹µì´ ì•„ë‹ˆê±°ë‚˜ ë§ˆì§€ë§‰ ì‹œë„ë¼ë©´ ê²°ê³¼ ë°˜í™˜
            if not is_rejection or attempt == max_retries - 1:
                if is_rejection and attempt == max_retries - 1:
                    print(f"ê²½ê³ : ëª¨ë“  ì¬ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return result_text
            
            # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
            print(f"ê±°ë¶€ ì‘ë‹µìœ¼ë¡œ ì¸í•œ ì¬ì‹œë„ ëŒ€ê¸° ì¤‘... (2ì´ˆ)")
            time.sleep(2)
            
        except Exception as e:
            print(f"GPT API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                raise
            # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
            import time
            time.sleep(2)
    
    return "ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


def analyze_image_gpt(image_base):
    """GPTì™€ OpenSearch RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        image_base (str): ë¶„ì„í•  ì´ë¯¸ì§€ì˜ ê¸°ë³¸ íŒŒì¼ëª… (ì˜ˆ: test4)
        
    Returns:
        dict: ë¶„ì„ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    if not OPENAI_API_KEY:
        print("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None

    if not os.path.exists(IMAGE_DIR):
        print(f"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {IMAGE_DIR}")
        return None

    target_filename = f"detection_result_{image_base}.jpg"
    image_path = os.path.join(IMAGE_DIR, target_filename)
    
    if not os.path.exists(image_path):
        print(f"{IMAGE_DIR} í´ë”ì— {target_filename} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    print(f"\n===== {target_filename} ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ =====")
    
    import time
    analysis_start_time = time.time()
    
    try:
        # 1ì°¨ GPT í•´ì„ (ì´ˆê¸° ë¶„ì„ - JSON)
        print("1ë‹¨ê³„: ì´ˆê¸° ì‹¬ë¦¬ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        initial_analysis_text = analyze_image_with_gpt(image_path, PROMPT)
        
        try:
            initial_analysis = json.loads(initial_analysis_text)
            print("ì´ˆê¸° ë¶„ì„ JSON íŒŒì‹± ì„±ê³µ")
        except json.JSONDecodeError:
            print("ì´ˆê¸° ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ ì‹œë„")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ìƒì„±
            initial_analysis = {
                "features": {"overall": ["ë¶„ì„ ì‹¤íŒ¨"]}, 
                "keywords": [], 
                "summary": initial_analysis_text
            }

        # ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì¶”ì¶œ (JSONì—ì„œ í‚¤ì›Œë“œ ë° íŠ¹ì§• ì¶”ì¶œ)
        print("\n2ë‹¨ê³„: ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì¶”ì¶œ ì¤‘...")
        psychological_elements = []
        if "keywords" in initial_analysis:
            psychological_elements.extend(initial_analysis["keywords"])
        
        if "features" in initial_analysis:
            for category, features in initial_analysis["features"].items():
                psychological_elements.extend(features)
                
        print(f"ì¶”ì¶œëœ ìš”ì†Œë“¤ (ìƒìœ„ 10ê°œ): {psychological_elements[:10]}")
        
        # OpenSearch RAG ê²€ìƒ‰
        print("\n3ë‹¨ê³„: RAG ì‹œìŠ¤í…œì„ í†µí•œ ê´€ë ¨ ìë£Œ ê²€ìƒ‰ ì¤‘...")
        rag_result = search_rag_documents(psychological_elements[:5]) # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
        
        final_analysis = initial_analysis
        
        if rag_result:
            print(f"ê²€ìƒ‰ëœ ê´€ë ¨ ìë£Œ: {rag_result['document']} - {rag_result['element']}")
            
            # RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ìµœì¢… ë¶„ì„ (JSON í˜•ì‹ ìœ ì§€)
            print("\n4ë‹¨ê³„: RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ìµœì¢… ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
            final_prompt = f"""
            ì•„ë˜ëŠ” ì‹¬ë¦¬ ê·¸ë¦¼ ê²€ì‚¬ì˜ ì´ˆê¸° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:
            {json.dumps(initial_analysis, ensure_ascii=False, indent=2)}

            ì°¸ê³  ìë£Œ:
            ë¬¸ì„œ: {rag_result['document']} - {rag_result['element']}
            ë‚´ìš©: {rag_result['text']}

            ìœ„ ë¶„ì„ ê²°ê³¼ì™€ ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë”ìš± ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ìµœì¢… ì‹¬ë¦¬ ë¶„ì„ì„ JSON í˜•ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
            ì´ˆê¸° ë¶„ì„ì˜ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë˜, ë‚´ìš©ì„ ë³´ê°•í•´ ì£¼ì„¸ìš”.
            """
            
            final_analysis_text = analyze_image_with_gpt(image_path, final_prompt)
            try:
                final_analysis = json.loads(final_analysis_text)
                print("ìµœì¢… ë¶„ì„ JSON íŒŒì‹± ì„±ê³µ")
            except json.JSONDecodeError:
                print("ìµœì¢… ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨, ì´ˆê¸° ë¶„ì„ ê²°ê³¼ ì‚¬ìš©")

        # ê²°ê³¼ êµ¬ì„±
        result_text = final_analysis.get("summary", "")
        if not result_text and "psychological_analysis" in final_analysis:
             # summaryê°€ ì—†ìœ¼ë©´ í•´ì„ì„ í•©ì³ì„œ ìƒì„±
             analysis = final_analysis["psychological_analysis"]
             result_text = f"ì§‘: {analysis.get('house', '')}\në‚˜ë¬´: {analysis.get('tree', '')}\nì‚¬ëŒ: {analysis.get('person', '')}"

        # ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        enriched = []
        if rag_result:
            enriched.append({
                'element': rag_result['element'],
                'condition': rag_result['text'][:100] + '...' if len(rag_result['text']) > 100 else rag_result['text'],
                'keywords': rag_result['metadata'].get('keywords', [])
            })

        result = {
            "raw_text": json.dumps(final_analysis, ensure_ascii=False), # í˜¸í™˜ì„±ì„ ìœ„í•´ JSON ë¬¸ìì—´ ì €ì¥
            "result_text": result_text,
            "items": enriched,
            "rag_context": rag_result,
            "parsed_result": final_analysis # íŒŒì‹±ëœ ê²°ê³¼ë„ ì €ì¥
        }
        
        analysis_end_time = time.time()
        print(f"âœ… [TIMING] ì‹¬ë¦¬ ë¶„ì„ ì „ì²´ ì™„ë£Œ: {analysis_end_time - analysis_start_time:.2f}ì´ˆ")
        
        return result

    except Exception as e:
        print(f"ë¶„ì„ ì‹¤íŒ¨ - ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì ì²˜ë¦¬"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ë¶„ì„í•  detection_result_*.jpg íŒŒì¼ëª…ì„ ì§€ì •í•˜ì„¸ìš”.")
    parser.add_argument('--image', type=str, required=True, help='ë¶„ì„í•  detection_result_*.jpg íŒŒì¼ëª… (ì˜ˆ: detection_result_test4.jpg)')
    args = parser.parse_args()

    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±° (test4.jpg â†’ test4, test4 â†’ test4)
    image_base = os.path.splitext(args.image)[0]
    
    # ìƒˆë¡œìš´ ëª¨ë“ˆí™”ëœ í•¨ìˆ˜ í˜¸ì¶œ
    result = analyze_image_gpt(image_base)
    
    if result is None:
        print("ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    print("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 
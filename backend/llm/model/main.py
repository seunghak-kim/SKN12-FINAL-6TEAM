import os
import sys
import json
import logging
import traceback
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from crop_by_labels import crop_objects_by_labels
from analyze_images_with_gpt import analyze_image_gpt
from keyword_classifier import run_keyword_prediction_from_result

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(__file__))


class PipelineStatus(Enum):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìƒíƒœ"""
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    ERROR = "error"
    FAILED = "failed"


class PersonalityType(Enum):
    """ì„±ê²© ìœ í˜• ë¶„ë¥˜"""
    CHUJIN = "ì¶”ì§„í˜•"  # ì¶”ì§„ì´
    NAEMYEON = "ë‚´ë©´í˜•"  # ë‚´ë©´ì´
    GWANGYE = "ê´€ê³„í˜•"  # ê´€ê³„ì´
    KWAERAK = "ì¾Œë½í˜•"  # ì¾Œë½ì´
    ANJEONG = "ì•ˆì •í˜•"  # ì•ˆì •ì´


@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì • í´ë˜ìŠ¤"""
    model_dir: Path
    test_img_dir: Path
    detection_results_dir: Path
    rag_dir: Path
    log_dir: Path
    
    # íŒŒì¼ í˜•ì‹ ì„¤ì •
    supported_image_formats: tuple = ('.jpg', '.jpeg', '.png')
    
    # ëª¨ë¸ ì„¤ì •  
    yolo_model_path: str = "best.pt"
    kobert_model_path: str = "kobert_model"
    
    # API ì„¤ì •
    openai_api_timeout: int = 120
    max_retries: int = 3


@dataclass 
class PipelineResult:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼"""
    status: PipelineStatus
    image_base: str
    timestamp: datetime
    
    # ê° ë‹¨ê³„ë³„ ê²°ê³¼
    detection_success: bool = False
    analysis_success: bool = False
    classification_success: bool = False
    
    # ê²°ê³¼ ë°ì´í„°
    detected_objects: Optional[Dict] = None
    psychological_analysis: Optional[Dict] = None
    personality_type: Optional[str] = None
    confidence_score: Optional[float] = None
    
    # ì˜¤ë¥˜ ì •ë³´
    error_message: Optional[str] = None
    error_stage: Optional[str] = None
    traceback: Optional[str] = None


class HTPAnalysisPipeline:
    """HTP ì‹¬ë¦¬ê²€ì‚¬ ì´ë¯¸ì§€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Optional[PipelineConfig] = None):
        """íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            config: íŒŒì´í”„ë¼ì¸ ì„¤ì •. Noneì´ë©´ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
        """
        self.config = config or self._create_default_config()
        self.logger = self._setup_logging()
        self._validate_environment()
    
    def _create_default_config(self) -> PipelineConfig:
        """ê¸°ë³¸ ì„¤ì • ìƒì„±"""
        base_dir = Path(__file__).parent
        return PipelineConfig(
            model_dir=base_dir,
            test_img_dir=base_dir / "../test_images",
            detection_results_dir=base_dir / "../detection_results", 
            rag_dir=base_dir / "../rag",
            log_dir=base_dir / "../logs"
        )
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        self.config.log_dir.mkdir(parents=True, exist_ok=True)
        
        # ë¡œê±° ìƒì„±
        logger = logging.getLogger('htp_pipeline')
        logger.setLevel(logging.INFO)
        
        # í•¸ë“¤ëŸ¬ê°€ ì´ë¯¸ ìˆë‹¤ë©´ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        if logger.handlers:
            logger.handlers.clear()
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        log_file = self.config.log_dir / f"pipeline_{datetime.now().strftime('%Y%m%d')}.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§¤í„° ì„¤ì •
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def _validate_environment(self) -> None:
        """í™˜ê²½ ê²€ì¦"""
        self.logger.info("í™˜ê²½ ê²€ì¦ ì‹œì‘...")
        
        # í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
        directories = [
            self.config.test_img_dir,
            self.config.detection_results_dir / "images",
            self.config.detection_results_dir / "results"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            self.logger.info(f"ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: {directory}")
        
        # YOLO ëª¨ë¸ íŒŒì¼ í™•ì¸
        yolo_model = self.config.model_dir / self.config.yolo_model_path
        if not yolo_model.exists():
            raise FileNotFoundError(f"YOLO ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {yolo_model}")
        
        # OpenAI API í‚¤ í™•ì¸
        if not os.getenv('OPENAI_API_KEY'):
            self.logger.warning("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.logger.info("í™˜ê²½ ê²€ì¦ ì™„ë£Œ")
    
    def _validate_image_file(self, image_path: Path) -> bool:
        """ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            bool: ìœ íš¨í•œ ì´ë¯¸ì§€ íŒŒì¼ì¸ì§€ ì—¬ë¶€
        """
        if not image_path.exists():
            self.logger.error(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}")
            return False
        
        if image_path.suffix.lower() not in self.config.supported_image_formats:
            self.logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: {image_path.suffix}")
            return False
        
        # íŒŒì¼ í¬ê¸° í™•ì¸ (ìµœëŒ€ 10MB)
        if image_path.stat().st_size > 10 * 1024 * 1024:
            self.logger.error(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ (>10MB): {image_path}")
            return False
        
        return True
    
    def _execute_stage_1(self, image_path: Path, result: PipelineResult) -> bool:
        """1ë‹¨ê³„: YOLO ê°ì²´ íƒì§€ ë° í¬ë¡­í•‘
        
        Args:
            image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            result: ê²°ê³¼ ì €ì¥ ê°ì²´
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info("[1/3] YOLO ê°ì²´ íƒì§€ ë° í¬ë¡­í•‘ ì‹œì‘...")
            
            # ê°ì²´ íƒì§€ ì‹¤í–‰
            detection_result = crop_objects_by_labels(str(image_path))
            
            # ê²°ê³¼ ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
            detection_image_path = (
                self.config.detection_results_dir / "images" / 
                f"detection_result_{result.image_base}.jpg"
            )
            
            if detection_image_path.exists():
                result.detection_success = True
                result.detected_objects = {"detection_image": str(detection_image_path)}
                self.logger.info(f"ê°ì²´ íƒì§€ ì™„ë£Œ: {detection_image_path}")
                return True
            else:
                self.logger.error("ê°ì²´ íƒì§€ ê²°ê³¼ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            self.logger.error(f"ê°ì²´ íƒì§€ ë‹¨ê³„ ì˜¤ë¥˜: {str(e)}")
            result.error_stage = "detection"
            result.error_message = str(e)
            return False
    
    def _execute_stage_2(self, result: PipelineResult) -> bool:
        """2ë‹¨ê³„: GPT-4 Vision ì‹¬ë¦¬ ë¶„ì„
        
        Args:
            result: ê²°ê³¼ ì €ì¥ ê°ì²´
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info("[2/3] GPT-4 Vision ì‹¬ë¦¬ ë¶„ì„ ì‹œì‘...")
            
            # GPT ë¶„ì„ ì‹¤í–‰
            analysis_result = analyze_image_gpt(result.image_base)
            
            # ê²°ê³¼ íŒŒì¼ í™•ì¸
            analysis_file_path = (
                self.config.detection_results_dir / "results" / 
                f"result_{result.image_base}.json"
            )
            
            if analysis_file_path.exists():
                # ë¶„ì„ ê²°ê³¼ ë¡œë“œ
                with open(analysis_file_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
                
                result.analysis_success = True
                result.psychological_analysis = analysis_data
                self.logger.info(f"ì‹¬ë¦¬ ë¶„ì„ ì™„ë£Œ: {analysis_file_path}")
                
                # GPT ì‘ë‹µ ê²€ì¦
                if self._validate_gpt_response(analysis_data):
                    return True
                else:
                    self.logger.warning("GPT ì‘ë‹µì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.")
                    return False
            else:
                self.logger.error("ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            self.logger.error(f"ì‹¬ë¦¬ ë¶„ì„ ë‹¨ê³„ ì˜¤ë¥˜: {str(e)}")
            result.error_stage = "analysis"
            result.error_message = str(e)
            return False
    
    def _validate_gpt_response(self, analysis_data: Dict) -> bool:
        """GPT ì‘ë‹µ ê²€ì¦
        
        Args:
            analysis_data: GPT ë¶„ì„ ê²°ê³¼
            
        Returns:
            bool: ìœ íš¨í•œ ì‘ë‹µì¸ì§€ ì—¬ë¶€
        """
        # ê¸°ë³¸ í•„ë“œ í™•ì¸
        required_fields = ['raw_text', 'result_text', 'items']
        for field in required_fields:
            if field not in analysis_data:
                self.logger.error(f"GPT ì‘ë‹µì— í•„ìˆ˜ í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤: {field}")
                return False
        
        # ì˜¤ë¥˜ ì‘ë‹µ íŒ¨í„´ í™•ì¸
        error_patterns = [
            "I'm sorry. I can't help with this request",
            "ì‚¬ëŒê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤",
            "ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            "ì£„ì†¡í•©ë‹ˆë‹¤"
        ]
        
        raw_text = analysis_data.get('raw_text', '').lower()
        for pattern in error_patterns:
            if pattern.lower() in raw_text:
                self.logger.warning(f"GPT ì˜¤ë¥˜ íŒ¨í„´ ê°ì§€: {pattern}")
                return False
        
        return True
    
    def _execute_stage_3(self, result: PipelineResult) -> bool:
        """3ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ì„±ê²© ìœ í˜• ë¶„ë¥˜ (best_keyword_classifier.pth ì‚¬ìš©)
        
        Args:
            result: ê²°ê³¼ ì €ì¥ ê°ì²´
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info("[3/3] í‚¤ì›Œë“œ ê¸°ë°˜ ì„±ê²© ìœ í˜• ë¶„ë¥˜ ì‹œì‘...")
            
            # í‚¤ì›Œë“œ ë¶„ë¥˜ê¸° ì‹¤í–‰
            try:
                # í‚¤ì›Œë“œ ê¸°ë°˜ ì„±ê²© ìœ í˜• ì˜ˆì¸¡ ì‹¤í–‰
                prediction_result = run_keyword_prediction_from_result(result.image_base, quiet=False)
                
                if prediction_result and prediction_result.get('personality_type'):
                    result.classification_success = True
                    result.personality_type = prediction_result.get('personality_type')
                    result.confidence_score = prediction_result.get('confidence', 0.0)
                    
                    self.logger.info(
                        f"í‚¤ì›Œë“œ ê¸°ë°˜ ì„±ê²© ìœ í˜• ë¶„ë¥˜ ì™„ë£Œ: {result.personality_type} "
                        f"(ì‹ ë¢°ë„: {result.confidence_score:.3f})"
                    )
                    return True
                else:
                    self.logger.error("í‚¤ì›Œë“œ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    return False
                    
            except ImportError as e:
                self.logger.error(f"í‚¤ì›Œë“œ ë¶„ë¥˜ê¸° import ì‹¤íŒ¨: {e}")
                return False
                
        except Exception as e:
            self.logger.error(f"ì„±ê²© ìœ í˜• ë¶„ë¥˜ ë‹¨ê³„ ì˜¤ë¥˜: {str(e)}")
            result.error_stage = "classification"
            result.error_message = str(e)
            return False
    

    
    def analyze_image(self, image_input: str) -> PipelineResult:
        """ì´ë¯¸ì§€ ë¶„ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            image_input: ì´ë¯¸ì§€ íŒŒì¼ëª… ë˜ëŠ” ê²½ë¡œ
            
        Returns:
            PipelineResult: ë¶„ì„ ê²°ê³¼
        """
        # ì´ë¯¸ì§€ íŒŒì¼ëª… ì •ê·œí™”
        image_base = Path(image_input).stem
        if not image_base:
            image_base = str(image_input)
        
        # ê²°ê³¼ ê°ì²´ ì´ˆê¸°í™”
        result = PipelineResult(
            status=PipelineStatus.RUNNING,
            image_base=image_base,
            timestamp=datetime.now()
        )
        
        self.logger.info(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {image_base}")
        
        try:
            # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ êµ¬ì„±
            image_path = self.config.test_img_dir / f"{image_base}.jpg"
            
            # ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦
            if not self._validate_image_file(image_path):
                result.status = PipelineStatus.FAILED
                result.error_message = "ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ íŒŒì¼"
                return result
            
            # 1ë‹¨ê³„: ê°ì²´ íƒì§€
            if not self._execute_stage_1(image_path, result):
                result.status = PipelineStatus.ERROR
                return result
            
            # 2ë‹¨ê³„: ì‹¬ë¦¬ ë¶„ì„
            if not self._execute_stage_2(result):
                result.status = PipelineStatus.ERROR
                return result
            
            # 3ë‹¨ê³„: ì„±ê²© ë¶„ë¥˜
            if not self._execute_stage_3(result):
                result.status = PipelineStatus.ERROR
                return result
            
            # ëª¨ë“  ë‹¨ê³„ ì„±ê³µ
            result.status = PipelineStatus.SUCCESS
            self.logger.info(f"ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ: {image_base} -> {result.personality_type}")
            
        except Exception as e:
            self.logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            result.status = PipelineStatus.ERROR
            result.error_message = str(e)
            result.traceback = traceback.format_exc()
        
        return result
    
    def get_analysis_status(self, image_base: str) -> Dict[str, Any]:
        """ë¶„ì„ ìƒíƒœ ì¡°íšŒ
        
        Args:
            image_base: ì´ë¯¸ì§€ ê¸°ë³¸ëª…
            
        Returns:
            Dict: ë¶„ì„ ìƒíƒœ ì •ë³´
        """
        status = {
            "image_base": image_base,
            "detection_completed": False,
            "analysis_completed": False,
            "classification_completed": False,
            "final_result": None
        }
        
        # ê° ë‹¨ê³„ë³„ ê²°ê³¼ íŒŒì¼ í™•ì¸
        detection_path = (
            self.config.detection_results_dir / "images" / 
            f"detection_result_{image_base}.jpg"
        )
        analysis_path = (
            self.config.detection_results_dir / "results" / 
            f"result_{image_base}.json"
        )
        
        # KoBERT ê²°ê³¼ íŒŒì¼ í™•ì¸ (result.jsonì˜ personality_analysis ì¡´ì¬ ì—¬ë¶€)
        kobert_completed = False
        if analysis_path.exists():
            try:
                with open(analysis_path, 'r', encoding='utf-8') as f:
                    result_data = json.load(f)
                    kobert_completed = 'personality_analysis' in result_data
            except:
                kobert_completed = False
        
        status["detection_completed"] = detection_path.exists()
        status["analysis_completed"] = analysis_path.exists()
        status["classification_completed"] = kobert_completed
        
        self.logger.info(f"ìƒíƒœ í™•ì¸ - íƒì§€: {status['detection_completed']}, ë¶„ì„: {status['analysis_completed']}, ë¶„ë¥˜: {status['classification_completed']}")
        self.logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸:")
        self.logger.info(f"  íƒì§€: {detection_path} (ì¡´ì¬: {detection_path.exists()})")
        self.logger.info(f"  ë¶„ì„: {analysis_path} (ì¡´ì¬: {analysis_path.exists()})")
        self.logger.info(f"  ë¶„ë¥˜: {kobert_path} (ì¡´ì¬: {kobert_path.exists()})")
        
        if analysis_path.exists():
            try:
                with open(analysis_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
                status["final_result"] = analysis_data
            except Exception as e:
                self.logger.error(f"ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        
        return status


def _display_detailed_keyword_results(image_base: str, pipeline: HTPAnalysisPipeline):
    """í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„¸í•˜ê²Œ ì¶œë ¥"""
    try:
        # ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
        result_file_path = pipeline.config.detection_results_dir / "results" / f"result_{image_base}.json"
        
        if not result_file_path.exists():
            print(f"\nâš ï¸  í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {result_file_path}")
            return
        
        # ê²°ê³¼ íŒŒì¼ ë¡œë“œ
        with open(result_file_path, 'r', encoding='utf-8') as f:
            result_data = json.load(f)
        
        # í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
        keyword_analysis = result_data.get('keyword_personality_analysis', {})
        
        if not keyword_analysis:
            print(f"\nâš ï¸  í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        print(f"\nğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ ì„±ê²© ë¶„ë¥˜ ìƒì„¸ ê²°ê³¼")
        print("="*50)
        
        # ì˜ˆì¸¡ëœ ì„±ê²© ìœ í˜•
        predicted_personality = keyword_analysis.get('predicted_personality', 'N/A')
        confidence = keyword_analysis.get('confidence', 0.0)
        print(f"ğŸ¯ ì˜ˆì¸¡ëœ ì„±ê²© ìœ í˜•: {predicted_personality}")
        print(f"ğŸ“Š ì‹ ë¢°ë„: {confidence:.3f} ({confidence*100:.1f}%)")
        
        # ì‚¬ìš©ëœ í‚¤ì›Œë“œë“¤
        current_keywords = keyword_analysis.get('current_image_keywords', [])
        previous_keywords = keyword_analysis.get('previous_stage_keywords', [])
        total_keywords = keyword_analysis.get('total_keywords_used', 0)
        
        print(f"\nğŸ”¤ ì‚¬ìš©ëœ í‚¤ì›Œë“œ ({total_keywords}ê°œ):")
        if current_keywords:
            print(f"  ğŸ“· í˜„ì¬ ì´ë¯¸ì§€ í‚¤ì›Œë“œ ({len(current_keywords)}ê°œ):")
            print(f"     {', '.join(current_keywords[:10])}")
            if len(current_keywords) > 10:
                print(f"     ... ì™¸ {len(current_keywords)-10}ê°œ")
        
        if previous_keywords:
            print(f"  ğŸ“š ì´ì „ ë‹¨ê³„ í‚¤ì›Œë“œ ({len(previous_keywords)}ê°œ):")
            print(f"     {', '.join(previous_keywords[:10])}")
            if len(previous_keywords) > 10:
                print(f"     ... ì™¸ {len(previous_keywords)-10}ê°œ")
        
        # ê° ìœ í˜•ë³„ í™•ë¥ 
        probabilities = keyword_analysis.get('probabilities', {})
        if probabilities:
            print(f"\nğŸ“ˆ ì„±ê²© ìœ í˜•ë³„ í™•ë¥ :")
            sorted_probs = sorted(probabilities.items(), key=lambda x: -x[1])
            for i, (persona_type, prob) in enumerate(sorted_probs):
                marker = "ğŸ†" if persona_type == predicted_personality else "  "
                bar_length = int(prob / 5)  # 100% = 20ì¹¸
                bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
                print(f"     {marker} {persona_type:6s}: {prob:5.1f}% [{bar}]")
        
        # ëª¨ë¸ ì •ë³´
        model_used = keyword_analysis.get('model_used', 'N/A')
        timestamp = keyword_analysis.get('analysis_timestamp', 'N/A')
        print(f"\nğŸ¤– ì‚¬ìš©ëœ ëª¨ë¸: {model_used}")
        print(f"â° ë¶„ì„ ì‹œê°„: {timestamp}")
        
        print("="*50)
        
    except Exception as e:
        print(f"\nâŒ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")


def main():
    """ë©”ì¸ í•¨ìˆ˜ - CLI ì¸í„°í˜ì´ìŠ¤"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ê±°ë¶ì´ìƒë‹´ì†Œ HTP ì‹¬ë¦¬ê²€ì‚¬ ì´ë¯¸ì§€ ë¶„ì„ íŒŒì´í”„ë¼ì¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python main.py --image test5.jpg
  python main.py --image test5 --verbose
  python main.py --image /path/to/image.png --config config.json
        """
    )
    
    parser.add_argument(
        '--image', 
        type=str, 
        required=True,
        help='ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ëª… (ì˜ˆ: test5.jpg, test5)'
    )
    parser.add_argument(
        '--verbose', 
        action='store_true',
        help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥'
    )
    parser.add_argument(
        '--config',
        type=str,
        help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON í˜•ì‹)'
    )
    
    args = parser.parse_args()
    
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    try:
        pipeline = HTPAnalysisPipeline()
        
        if args.verbose:
            pipeline.logger.setLevel(logging.DEBUG)
        
        # ë¶„ì„ ì‹¤í–‰
        result = pipeline.analyze_image(args.image)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("HTP ì‹¬ë¦¬ê²€ì‚¬ ë¶„ì„ ê²°ê³¼")
        print("="*60)
        print(f"ì´ë¯¸ì§€: {result.image_base}")
        print(f"ìƒíƒœ: {result.status.value}")
        print(f"ì‹œê°„: {result.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if result.status == PipelineStatus.SUCCESS:
            print(f"\nğŸ¯ ì„±ê²© ìœ í˜•: {result.personality_type}")
            print(f"ğŸ” ì‹ ë¢°ë„: {result.confidence_score:.1%}")
            
            # í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ìƒì„¸ ì¶œë ¥
            _display_detailed_keyword_results(result.image_base, pipeline)
            
            if result.psychological_analysis:
                print(f"\nğŸ“‹ ì‹¬ë¦¬ ë¶„ì„ ìš”ì•½:")
                print(result.psychological_analysis.get('result_text', 'N/A')[:200] + "...")
        
        elif result.status in [PipelineStatus.ERROR, PipelineStatus.FAILED]:
            print(f"\nâŒ ì˜¤ë¥˜: {result.error_message}")
            if result.error_stage:
                print(f"ì˜¤ë¥˜ ë‹¨ê³„: {result.error_stage}")
        
        print("="*60)
        
        # ìƒíƒœë³„ ì¢…ë£Œ ì½”ë“œ
        exit_codes = {
            PipelineStatus.SUCCESS: 0,
            PipelineStatus.ERROR: 1,
            PipelineStatus.FAILED: 2
        }
        
        sys.exit(exit_codes.get(result.status, 1))
        
    except Exception as e:
        print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        sys.exit(3)


if __name__ == "__main__":
    main()
"""
ê±°ë¶ì´ìƒë‹´ì†Œ HTP ì‹¬ë¦¬ê²€ì‚¬ íŒŒì´í”„ë¼ì¸ API
ì´ ëª¨ë“ˆì€ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
TestPage.tsxì—ì„œ ë²„íŠ¼ í´ë¦­ ì‹œ í˜¸ì¶œë˜ëŠ” í†µí•© íŒŒì´í”„ë¼ì¸ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
"""

from fastapi import APIRouter, HTTPException, Depends, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
from typing import Optional, Dict, Any
import os
import uuid
import json
import asyncio
from datetime import datetime
from pathlib import Path

# ë‚´ë¶€ ëª¨ë“ˆ
from ..database import get_db
from ..models.test import DrawingTest, DrawingTestResult
from ..models.user import UserInformation
from ..schemas.test import DrawingTestCreate, DrawingTestResultCreate
from .auth import get_current_user

# HTP íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ (ì ˆëŒ€ ê²½ë¡œë¡œ import)
import sys
project_root = Path(__file__).parent.parent.parent
pipeline_module_path = project_root / 'llm' / 'model'
sys.path.insert(0, str(pipeline_module_path))

try:
    from main import HTPAnalysisPipeline, PipelineStatus, PipelineResult
    PIPELINE_IMPORT_ERROR = None
    print("âœ… HTP íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ import ì„±ê³µ")
except Exception as e:
    import sys
    error_msg = str(e)
    print(f"âŒ HTP íŒŒì´í”„ë¼ì¸ import ì‹¤íŒ¨: {e}", file=sys.stderr)
    
    if "numpy.dtype size changed" in error_msg:
        print(f"ğŸ’¡ numpy/pandas ë²„ì „ ì¶©ëŒ í•´ê²°ë°©ë²•:", file=sys.stderr)
        print(f"   conda install -c conda-forge numpy pandas --force-reinstall", file=sys.stderr)
        print(f"   ë˜ëŠ” pip uninstall numpy pandas -y && pip install numpy pandas", file=sys.stderr)
    else:
        print(f"ğŸ’¡ ì¼ë°˜ì ì¸ í•´ê²°ë°©ë²•:", file=sys.stderr)
        print(f"   pip install pandas transformers ultralytics torch opencv-python scikit-learn", file=sys.stderr)
    
    HTPAnalysisPipeline = None
    PipelineStatus = None
    PipelineResult = None
    PIPELINE_IMPORT_ERROR = error_msg

router = APIRouter()

# ì „ì—­ íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤
pipeline_instance= None

def get_pipeline():
    """íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    global pipeline_instance
    if pipeline_instance is None:
        if HTPAnalysisPipeline is None:
            missing_packages = ["pandas", "transformers", "ultralytics", "torch", "opencv-python", "scikit-learn"]
            raise HTTPException(
                status_code=503,  # Service Unavailable
                detail={
                    "error": "HTP ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "reason": "í•„ìˆ˜ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "missing_packages": missing_packages,
                    "install_command": f"pip install {' '.join(missing_packages)}",
                    "status": "service_unavailable"
                }
            )
        pipeline_instance = HTPAnalysisPipeline()
    return pipeline_instance


@router.post("/analyze-image")
async def analyze_drawing_image(
    background_tasks: BackgroundTasks,
    file: Optional[UploadFile] = File(None),
    image: Optional[UploadFile] = File(None),
    description: Optional[str] = Form(None),
    db: Session = Depends(get_db),
    current_user: dict = Depends(get_current_user)
):
    """
    ê·¸ë¦¼ ì´ë¯¸ì§€ ë¶„ì„ API
    
    TestPage.tsxì˜ 'ë¶„ì„ ì‹œì‘í•˜ê¸°' ë²„íŠ¼ì—ì„œ í˜¸ì¶œë©ë‹ˆë‹¤.
    ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ HTP ì‹¬ë¦¬ê²€ì‚¬ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        file: ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼
        description: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê·¸ë¦¼ ì„¤ëª… (ì„ íƒì‚¬í•­)
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        current_user: í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì
        
    Returns:
        JSON: ë¶„ì„ ì‘ì—… ì‹œì‘ ì‘ë‹µ ë° ì‘ì—… ID
    """
    # file ë˜ëŠ” image ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš© (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±)
    upload_file = file or image
    
    print(f"ğŸ” API ì—”ë“œí¬ì¸íŠ¸ ì§„ì… - í•¨ìˆ˜ ì‹œì‘")
    print(f"ğŸ“‹ ìš”ì²­ íŒŒë¼ë¯¸í„° ì •ë³´:")
    print(f"  - file: {file}")
    print(f"  - image: {image}")
    print(f"  - upload_file: {upload_file}")
    print(f"  - filename: {getattr(upload_file, 'filename', 'N/A') if upload_file else 'N/A'}")
    print(f"  - content_type: {getattr(upload_file, 'content_type', 'N/A') if upload_file else 'N/A'}")
    print(f"  - description: {description}")
    print(f"  - current_user: {current_user}")
    
    try:
        if not upload_file:
            print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•ŠìŒ")
            raise HTTPException(
                status_code=422,
                detail="ì´ë¯¸ì§€ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'file' ë˜ëŠ” 'image' í•„ë“œì— íŒŒì¼ì„ ì²¨ë¶€í•´ì£¼ì„¸ìš”."
            )
        
        print(f"ğŸš€ ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­ ì‹œì‘ - ì‚¬ìš©ì: {current_user['user_id']}")
        print(f"ğŸ“ ì´ë¯¸ì§€ íŒŒì¼: {upload_file.filename}, í¬ê¸°: {upload_file.size if upload_file.size else 'unknown'}, íƒ€ì…: {upload_file.content_type}")
        print(f"ğŸ“ ì„¤ëª…: {description}")
        
        if not upload_file.filename:
            print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: íŒŒì¼ëª…ì´ ì—†ìŒ")
            raise HTTPException(
                status_code=422,
                detail="ì´ë¯¸ì§€ íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤."
            )
        
        # 1. íŒŒì¼ ê²€ì¦
        if not upload_file.content_type or not upload_file.content_type.startswith('image/'):
            print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: ì˜ëª»ëœ content-type: {upload_file.content_type}")
            raise HTTPException(
                status_code=422,
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
            )
        
        # 2. ê³ ìœ  íŒŒì¼ëª… ìƒì„±
        file_extension = Path(upload_file.filename).suffix.lower()
        if file_extension not in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']:
            print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: ì§€ì›í•˜ì§€ ì•ŠëŠ” í™•ì¥ì: {file_extension}")
            raise HTTPException(
                status_code=422,
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤. (.jpg, .jpeg, .png, .bmp, .gif ì§€ì›)"
            )
        
        unique_id = str(uuid.uuid4())
        image_filename = f"{unique_id}{file_extension}"
        
        # 3. ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì • (backend/result/images)
        backend_root = Path(__file__).parent.parent.parent
        upload_dir = backend_root / "result" / "images"
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        # 4. íŒŒì¼ ì €ì¥ (JPGë¡œ í†µì¼)
        image_path = upload_dir / f"{unique_id}.jpg"
        
        # 5. íŒŒì´í”„ë¼ì¸ìš© ë””ë ‰í† ë¦¬ì—ë„ ë³µì‚¬ (ê¸°ì¡´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í˜¸í™˜ì„±)
        pipeline = get_pipeline()
        pipeline_upload_dir = pipeline.config.test_img_dir
        pipeline_upload_dir.mkdir(parents=True, exist_ok=True)
        pipeline_image_path = pipeline_upload_dir / f"{unique_id}.jpg"
        
        # ì´ë¯¸ì§€ë¥¼ JPG í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        import PIL.Image as PILImage
        import io
        
        # ì—…ë¡œë“œëœ íŒŒì¼ì„ PIL Imageë¡œ ë¡œë“œ
        image_data = await upload_file.read()
        pil_image = PILImage.open(io.BytesIO(image_data))
        
        # RGB ëª¨ë“œë¡œ ë³€í™˜ (RGBA ë“± ë‹¤ë¥¸ ëª¨ë“œ ì²˜ë¦¬)
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # JPGë¡œ ì €ì¥ (backend/result/images)
        pil_image.save(image_path, 'JPEG', quality=95)
        
        # íŒŒì´í”„ë¼ì¸ìš© ë””ë ‰í† ë¦¬ì—ë„ ì €ì¥
        pil_image.save(pipeline_image_path, 'JPEG', quality=95)
        
        # 6. ë°ì´í„°ë² ì´ìŠ¤ì— í…ŒìŠ¤íŠ¸ ë ˆì½”ë“œ ìƒì„±
        drawing_test = DrawingTest(
            user_id=current_user["user_id"],
            image_url=f"result/images/{unique_id}.jpg",  # backend/result/images ê²½ë¡œ
            submitted_at=datetime.now()
        )
        
        db.add(drawing_test)
        db.commit()
        db.refresh(drawing_test)
        
        # 7. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹¤í–‰
        background_tasks.add_task(
            run_analysis_pipeline,
            unique_id,
            drawing_test.test_id,
            description
        )
        
        return JSONResponse(
            status_code=202,  # Accepted
            content={
                "message": "ì´ë¯¸ì§€ ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "test_id": drawing_test.test_id,
                "task_id": unique_id,
                "status": "processing",
                "estimated_time": "2-3ë¶„ ì†Œìš” ì˜ˆìƒ"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


def run_analysis_pipeline(
    unique_id: str,
    test_id: int,
    description: Optional[str]
):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” HTP ë¶„ì„ íŒŒì´í”„ë¼ì¸
    
    Args:
        unique_id: ê³ ìœ  ì´ë¯¸ì§€ ID
        test_id: ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ID
        description: ì‚¬ìš©ì ì„¤ëª…
    """
    # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ìš© ìƒˆ DB ì„¸ì…˜ ìƒì„± (HTTP ìš”ì²­ ì„¸ì…˜ê³¼ ë…ë¦½ì )
    from ..database import SessionLocal
    db = SessionLocal()
    
    try:
        print(f"ğŸš€ ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì‹œì‘: {unique_id}")
        
        # ë¶„ì„ ì‹œì‘ ì „ì— í…ŒìŠ¤íŠ¸ê°€ ì—¬ì „íˆ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        existing_test = db.query(DrawingTest).filter(
            DrawingTest.test_id == test_id
        ).first()
        
        if not existing_test:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ê°€ ì‚­ì œë¨ - ë¶„ì„ ì¤‘ë‹¨: test_id={test_id}")
            return
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = get_pipeline()
        result: PipelineResult = pipeline.analyze_image(unique_id)
        
        print(f"ğŸ“Š íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ: {result.status}")
        
        # ê²°ê³¼ ì €ì¥ ì „ì— ë‹¤ì‹œ í…ŒìŠ¤íŠ¸ ì¡´ì¬ í™•ì¸
        existing_test = db.query(DrawingTest).filter(
            DrawingTest.test_id == test_id
        ).first()
        
        if not existing_test:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ê°€ ë¶„ì„ ì¤‘ì— ì‚­ì œë¨ - ê²°ê³¼ ì €ì¥ ìƒëµ: test_id={test_id}")
            return
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ë™ê¸° í•¨ìˆ˜ë¡œ ë³€ê²½)
        print(f"ğŸ”¥ save_analysis_result_sync í•¨ìˆ˜ í˜¸ì¶œ ì‹œì‘ - test_id: {test_id}")
        save_analysis_result_sync(result, test_id, description, db)
        print(f"ğŸ”¥ save_analysis_result_sync í•¨ìˆ˜ í˜¸ì¶œ ì™„ë£Œ - test_id: {test_id}")
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ ë° ì €ì¥: {unique_id}")
        
    except Exception as e:
        print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ í…ŒìŠ¤íŠ¸ ì¡´ì¬ í™•ì¸
        try:
            existing_test = db.query(DrawingTest).filter(
                DrawingTest.test_id == test_id
            ).first()
            
            if not existing_test:
                print(f"âš ï¸ í…ŒìŠ¤íŠ¸ê°€ ì‚­ì œë¨ - ì˜¤ë¥˜ ìƒíƒœ ì €ì¥ ìƒëµ: test_id={test_id}")
                return
        except:
            print(f"í…ŒìŠ¤íŠ¸ ì¡´ì¬ í™•ì¸ ì‹¤íŒ¨: {test_id}")
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ì— ì˜¤ë¥˜ ìƒíƒœ ì €ì¥
        try:
            pipeline = get_pipeline()
            pipeline.logger.error(f"ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        except:
            print(f"íŒŒì´í”„ë¼ì¸ ë¡œê±° ì‚¬ìš© ë¶ˆê°€: {str(e)}")
        
        # ë¹ˆ ê²°ê³¼ë¡œ ì˜¤ë¥˜ ìƒíƒœ ì €ì¥
        try:
            error_result = DrawingTestResult(
                test_id=test_id,
                persona_type=None,
                summary_text=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                created_at=datetime.now()
            )
            
            db.add(error_result)
            db.commit()
            print(f"ì˜¤ë¥˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ: {test_id}")
        except Exception as db_error:
            print(f"ì˜¤ë¥˜ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {db_error}")
    finally:
        db.close()



def save_analysis_result_sync(
    result: Any,  # PipelineResultê°€ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ Any ì‚¬ìš©
    test_id: int,
    description: Optional[str],
    db: Session
):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ê°„ì†Œí™”ëœ ì§ì ‘ ì €ì¥ ë²„ì „)
    JSON íŒŒì¼ ì˜ì¡´ì„± ì œê±°í•˜ê³  íŒŒì´í”„ë¼ì¸ ê²°ê³¼ë¥¼ ì§ì ‘ í™œìš©
    
    Args:
        result: íŒŒì´í”„ë¼ì¸ ë¶„ì„ ê²°ê³¼
        test_id: ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ID
        description: ì‚¬ìš©ì ì„¤ëª…
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    """
    print(f"ğŸ”¥ save_analysis_result_sync í•¨ìˆ˜ ì§„ì… - test_id: {test_id}")
    
    try:
        # íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        pipeline = get_pipeline()
        
        # ì„±ê²© ìœ í˜•ì„ personas í…Œì´ë¸”ì˜ IDë¡œ ë§¤í•‘
        personality_mapping = {
            "ì¶”ì§„í˜•": 1,  # ì¶”ì§„ì´
            "ë‚´ë©´í˜•": 2,  # ë‚´ë©´ì´  
            "ê´€ê³„í˜•": 3,  # ê´€ê³„ì´
            "ì¾Œë½í˜•": 4,  # ì¾Œë½ì´
            "ì•ˆì •í˜•": 5   # ì•ˆì •ì´
        }
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        persona_type_id = 2  # ê¸°ë³¸ê°’: ë‚´ë©´í˜•
        summary_text = "ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        persona_scores = {
            'dog_scores': 0.0,     # ì¶”ì§„í˜•
            'cat_scores': 0.0,     # ë‚´ë©´í˜•
            'rabbit_scores': 0.0,  # ê´€ê³„í˜•
            'bear_scores': 0.0,    # ì¾Œë½í˜•
            'turtle_scores': 0.0   # ì•ˆì •í˜•
        }
        
        # íŒŒì´í”„ë¼ì¸ ê²°ê³¼ê°€ ì„±ê³µì ì¸ ê²½ìš° ì²˜ë¦¬
        if (PipelineStatus is not None and 
            hasattr(result, 'status') and 
            result.status == PipelineStatus.SUCCESS):
            
            print(f"ğŸ“Š íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì²˜ë¦¬ ì‹œì‘")
            
            # 1. í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ìš°ì„  ì²˜ë¦¬ (result ê°ì²´ì— ì§ì ‘ í¬í•¨ëœ ê²½ìš°)
            if hasattr(result, 'keyword_analysis') and result.keyword_analysis:
                keyword_data = result.keyword_analysis
                print(f"ğŸ” í‚¤ì›Œë“œ ë¶„ì„ ë°ì´í„° ë°œê²¬: {keyword_data}")
                
                predicted_personality = keyword_data.get('predicted_personality')
                confidence = keyword_data.get('confidence', 0.0)
                probabilities = keyword_data.get('probabilities', {})
                
                if probabilities:
                    # í™•ë¥ ì—ì„œ ê°€ì¥ ë†’ì€ ìœ í˜• ì°¾ê¸°
                    highest_prob_type = max(probabilities.items(), key=lambda x: x[1])[0]
                    highest_prob_value = probabilities[highest_prob_type]
                    
                    # ìµœê³  í™•ë¥  ìœ í˜•ì„ persona_type_idë¡œ ë§¤í•‘
                    persona_type_id = personality_mapping.get(highest_prob_type, 2)
                    
                    # í™•ë¥ ê°’ì„ DB í•„ë“œì— ë§¤í•‘ (DECIMAL(5,2) ì œí•œì— ë§ê²Œ ë³€í™˜: ìµœëŒ€ 999.99)
                    persona_scores.update({
                        'dog_scores': round(min(probabilities.get('ì¶”ì§„í˜•', 0.0), 999.99), 2),
                        'cat_scores': round(min(probabilities.get('ë‚´ë©´í˜•', 0.0), 999.99), 2),
                        'rabbit_scores': round(min(probabilities.get('ê´€ê³„í˜•', 0.0), 999.99), 2),
                        'bear_scores': round(min(probabilities.get('ì¾Œë½í˜•', 0.0), 999.99), 2),
                        'turtle_scores': round(min(probabilities.get('ì•ˆì •í˜•', 0.0), 999.99), 2)
                    })
                    
                    print(f"âœ… í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì ìš©:")
                    print(f"  - ìµœê³  í™•ë¥  ìœ í˜•: {highest_prob_type} ({highest_prob_value:.1f}%)")
                    print(f"  - persona_type_id: {persona_type_id}")
                    print(f"  - í™•ë¥  ë¶„í¬: {probabilities}")
            
            # 2. ê¸°ë³¸ ì„±ê²© ìœ í˜• ê²°ê³¼ ì²˜ë¦¬
            elif hasattr(result, 'personality_type') and result.personality_type:
                persona_type_id = personality_mapping.get(result.personality_type, 2)
                print(f"ğŸ“ ê¸°ë³¸ ì„±ê²© ìœ í˜• ì ìš©: {result.personality_type} -> ID: {persona_type_id}")
            
            # 3. GPT ì‹¬ë¦¬ ë¶„ì„ í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬ (í‚¤ì›Œë“œ/ê¸°ë³¸ ë¶„ì„ ì •ë³´ ì œì™¸)
            summary_text = "ì„±ê²© ìœ í˜• ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."  # ê¸°ë³¸ê°’
            
            if hasattr(result, 'psychological_analysis') and result.psychological_analysis:
                psych_analysis = result.psychological_analysis
                if isinstance(psych_analysis, dict) and psych_analysis.get('result_text'):
                    # GPT ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ë§Œ ì‚¬ìš© (ë‹¤ë¥¸ ì •ë³´ ì¶”ê°€ ì—†ì´)
                    summary_text = psych_analysis['result_text']
                    print(f"ğŸ“„ GPT ì‹¬ë¦¬ ë¶„ì„ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš© (ê¸°íƒ€ ì •ë³´ ì œì™¸)")
                else:
                    print(f"âš ï¸ GPT ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
            else:
                print(f"âš ï¸ psychological_analysis ë°ì´í„°ê°€ ì—†ìŒ")
            
            print(f"ğŸ“ ìµœì¢… summary_text ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(summary_text)}ì)")
            print(f"ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {summary_text[:100]}..." if len(summary_text) > 100 else f"ğŸ“ ì „ì²´ ë‚´ìš©: {summary_text}")
        
        # ì˜¤ë¥˜ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        elif hasattr(result, 'error_message') and result.error_message:
            summary_text = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result.error_message}"
            print(f"âŒ ì˜¤ë¥˜ ë©”ì‹œì§€: {result.error_message}")
        
        else:
            # ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš© (ì´ë¯¸ ì„¤ì •ëœ summary_text ì‚¬ìš©)
            print(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„. result ê°ì²´ ì†ì„±: {dir(result) if result else 'None'}")
            print(f"ğŸ“ ê¸°ë³¸ summary_text ì‚¬ìš©: {summary_text}")
        
        # ê²°ê³¼ ì €ì¥ (upsert íŒ¨í„´)
        existing_result = db.query(DrawingTestResult).filter(
            DrawingTestResult.test_id == test_id
        ).first()
        
        print(f"ğŸ’¾ DB ì €ì¥ ì „ ìµœì¢… í™•ì¸:")
        print(f"  - persona_type_id: {persona_type_id}")
        print(f"  - test_id: {test_id}")
        print(f"  - persona_scores: {persona_scores}")
        print(f"  - summary_text ê¸¸ì´: {len(summary_text)}ì")
        print(f"  - summary_text ìƒ˜í”Œ: {summary_text[:50]}..." if len(summary_text) > 50 else f"  - summary_text: {summary_text}")
        
        # DECIMAL ì œí•œ ê²€ì¦ ë° ì¡°ì •
        for key, value in persona_scores.items():
            if value > 999.99:
                print(f"âš ï¸ {key} ê°’ì´ DECIMAL(5,2) ì œí•œì„ ì´ˆê³¼í•¨: {value} -> 999.99ë¡œ ì¡°ì •")
                persona_scores[key] = 999.99
        
        print(f"ğŸ“Š ì¡°ì •ëœ persona_scores: {persona_scores}")
            
        if existing_result:
            # ê¸°ì¡´ ê²°ê³¼ ì—…ë°ì´íŠ¸
            print(f"ğŸ”„ ê¸°ì¡´ ê²°ê³¼ ì—…ë°ì´íŠ¸ - ì´ì „ persona_type: {existing_result.persona_type}")
            existing_result.persona_type = persona_type_id
            existing_result.summary_text = summary_text
            existing_result.created_at = datetime.now()
            
            # í™•ë¥  ì ìˆ˜ ì—…ë°ì´íŠ¸ (ì•ˆì „í•œ ê°’ìœ¼ë¡œ)
            existing_result.dog_scores = persona_scores['dog_scores']
            existing_result.cat_scores = persona_scores['cat_scores'] 
            existing_result.rabbit_scores = persona_scores['rabbit_scores']
            existing_result.bear_scores = persona_scores['bear_scores']
            existing_result.turtle_scores = persona_scores['turtle_scores']
            
            print(f"ğŸ”„ ì—…ë°ì´íŠ¸í•  ì ìˆ˜ë“¤: {persona_scores}")
            print(f"ğŸ”„ ì—…ë°ì´íŠ¸í•  summary_text ë¯¸ë¦¬ë³´ê¸°: {summary_text[:100]}..." if len(summary_text) > 100 else f"ğŸ”„ ì—…ë°ì´íŠ¸í•  summary_text: {summary_text}")
            
            print(f"ğŸ”„ ì—…ë°ì´íŠ¸ ì™„ë£Œ - ìƒˆ persona_type: {existing_result.persona_type}")
        else:
            # ìƒˆ ê²°ê³¼ ìƒì„±
            print(f"ğŸ†• ìƒˆ ê²°ê³¼ ìƒì„±")
            test_result_data = {
                'test_id': test_id,
                'persona_type': persona_type_id,
                'summary_text': summary_text,
                'created_at': datetime.now(),
                'dog_scores': persona_scores['dog_scores'],
                'cat_scores': persona_scores['cat_scores'],
                'rabbit_scores': persona_scores['rabbit_scores'],
                'bear_scores': persona_scores['bear_scores'],
                'turtle_scores': persona_scores['turtle_scores']
            }
            
            print(f"ğŸ†• ìƒˆë¡œ ìƒì„±í•  ë°ì´í„°: test_id={test_id}, persona_type={persona_type_id}")
            print(f"ğŸ†• ì ìˆ˜ ë°ì´í„°: {persona_scores}")
            print(f"ğŸ†• ìƒˆ summary_text ë¯¸ë¦¬ë³´ê¸°: {summary_text[:100]}..." if len(summary_text) > 100 else f"ğŸ†• ìƒˆ summary_text: {summary_text}")
            
            test_result = DrawingTestResult(**test_result_data)
            db.add(test_result)
            print(f"ğŸ†• ìƒˆ ê²°ê³¼ DBì— ì¶”ê°€ë¨ - persona_type: {persona_type_id}")
        
        print(f"ğŸ’¾ DB commit ì‹œì‘...")
        
        try:
            db.commit()
            print(f"âœ… DB commit ì„±ê³µ! ë¶„ì„ ê²°ê³¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"âœ… ìµœì¢… ì €ì¥ëœ summary_text: GPT ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ë§Œ í¬í•¨ ({len(summary_text)}ì)")
        except Exception as commit_error:
            print(f"âŒ DB commit ì˜¤ë¥˜: {str(commit_error)}")
            db.rollback()
            raise commit_error
        
        # íŒŒì´í”„ë¼ì¸ ë¡œê±°ì— ì„±ê³µ ë¡œê·¸ ê¸°ë¡
        try:
            pipeline.logger.info(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì„±ê³µ - test_id: {test_id}, persona_type: {persona_type_id}")
        except:
            print(f"ë¡œê±° ì‚¬ìš© ë¶ˆê°€, ì½˜ì†”ì— ê¸°ë¡: test_id: {test_id}, persona_type: {persona_type_id}")
        
    except Exception as e:
        print(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"ğŸ“Š ì—ëŸ¬ ìƒì„¸ ì •ë³´: {repr(e)}")
        
        # ì—ëŸ¬ íƒ€ì…ë³„ ìƒì„¸ ì •ë³´
        import traceback
        print(f"ğŸ” ì „ì²´ ì—ëŸ¬ íŠ¸ë ˆì´ìŠ¤:")
        traceback.print_exc()
        
        db.rollback()
        
        try:
            pipeline.logger.error(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        except:
            print(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜ (ë¡œê±° ì‚¬ìš© ë¶ˆê°€): {str(e)}")
        
        # ì˜¤ë¥˜ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œì„œ ìƒìœ„ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•¨
        raise


@router.get("/analysis-status/{test_id}")
async def get_analysis_status(
    test_id: int,
    db: Session = Depends(get_db),
    current_user: dict = Depends(get_current_user)
):
    """
    ë¶„ì„ ìƒíƒœ ì¡°íšŒ API
    
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë¶„ì„ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        test_id: í…ŒìŠ¤íŠ¸ ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        current_user: í˜„ì¬ ì‚¬ìš©ì
        
    Returns:
        JSON: ë¶„ì„ ìƒíƒœ ì •ë³´
    """
    try:
        # í…ŒìŠ¤íŠ¸ ë ˆì½”ë“œ ì¡°íšŒ
        drawing_test = db.query(DrawingTest).filter(
            DrawingTest.test_id == test_id,
            DrawingTest.user_id == current_user["user_id"]
        ).first()
        
        if not drawing_test:
            # í…ŒìŠ¤íŠ¸ê°€ ì‚­ì œëœ ê²½ìš° (ë¶„ì„ ì¤‘ë‹¨) - ì˜¤ë¥˜ê°€ ì•„ë‹Œ ì¤‘ë‹¨ëœ ìƒíƒœë¡œ ì²˜ë¦¬
            return JSONResponse(content={
                "test_id": test_id,
                "status": "cancelled",
                "message": "ë¶„ì„ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "steps": [],
                "current_step": 0,
                "completed_steps": 0,
                "total_steps": 3,
                "cancelled": True
            })
        
        # ê²°ê³¼ ì¡°íšŒ
        test_result = db.query(DrawingTestResult).filter(
            DrawingTestResult.test_id == test_id
        ).first()
        
        if not test_result:
            # íŒŒì´í”„ë¼ì¸ ì§„í–‰ìƒí™© í™•ì¸
            pipeline = get_pipeline()
            
            # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ (URLì—ì„œ íŒŒì¼ëª… ë¶€ë¶„ë§Œ)
            image_url = drawing_test.image_url  # "result/images/{unique_id}.jpg"
            if image_url:
                # "result/images/uuid.jpg" -> "uuid"
                import re
                match = re.search(r'result/images/(.+?)\.jpg', image_url)
                if match:
                    unique_id = match.group(1)
                    status_info = pipeline.get_analysis_status(unique_id)
                    
                    # ë‹¨ê³„ë³„ ì§„í–‰ìƒí™© êµ¬ì„±
                    detection_completed = status_info.get("detection_completed", False)
                    analysis_completed = status_info.get("analysis_completed", False)
                    classification_completed = status_info.get("classification_completed", False)
                    
                    steps = [
                        {
                            "name": "ê°ì²´ íƒì§€",
                            "description": "YOLOë¥¼ ì‚¬ìš©í•œ ê·¸ë¦¼ ìš”ì†Œ ê²€ì¶œ",
                            "completed": detection_completed,
                            "current": not detection_completed
                        },
                        {
                            "name": "ì‹¬ë¦¬ ë¶„ì„", 
                            "description": "GPT-4ë¥¼ ì‚¬ìš©í•œ ì‹¬ë¦¬ìƒíƒœ ë¶„ì„",
                            "completed": analysis_completed,
                            "current": detection_completed and not analysis_completed
                        },
                        {
                            "name": "ì„±ê²© ë¶„ë¥˜",
                            "description": "í‚¤ì›Œë“œ ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•œ ì„±ê²©ìœ í˜• ë¶„ë¥˜", 
                            "completed": classification_completed,
                            "current": analysis_completed and not classification_completed
                        }
                    ]
                    
                    # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë‹¨ê³„ ì°¾ê¸°
                    current_step = next((i+1 for i, step in enumerate(steps) if step["current"]), 1)
                    completed_steps = sum(1 for step in steps if step["completed"])
                    
                    # ëª¨ë“  ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if classification_completed:
                        # 3ë‹¨ê³„ ëª¨ë‘ ì™„ë£Œëœ ê²½ìš°, ìµœì¢… ê²°ê³¼ê°€ DBì— ì €ì¥ë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
                        print(f"ğŸ¯ ëª¨ë“  ë‹¨ê³„ ì™„ë£Œë¨ - ìµœì¢… ê²°ê³¼ ëŒ€ê¸° ì¤‘")
                        return JSONResponse(content={
                            "test_id": test_id,
                            "status": "processing",
                            "message": "ìµœì¢… ê²°ê³¼ ìƒì„± ì¤‘...",
                            "steps": steps,
                            "current_step": 3,
                            "completed_steps": 3,
                            "total_steps": 3,
                            "estimated_remaining": "ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”"
                        })
                    
                    return JSONResponse(content={
                        "test_id": test_id,
                        "status": "processing",
                        "message": f"ë‹¨ê³„ {current_step}/3 ì§„í–‰ ì¤‘...",
                        "steps": steps,
                        "current_step": current_step,
                        "completed_steps": completed_steps,
                        "total_steps": 3,
                        "estimated_remaining": f"{4-completed_steps}ë¶„ ì†Œìš” ì˜ˆìƒ"
                    })
            
            # ê¸°ë³¸ ì‘ë‹µ (íŒŒì¼ëª… ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ)
            return JSONResponse(content={
                "test_id": test_id,
                "status": "processing", 
                "message": "ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...",
                "steps": [
                    {"name": "ê°ì²´ íƒì§€", "description": "ê·¸ë¦¼ ìš”ì†Œ ê²€ì¶œ ì¤‘", "completed": False, "current": True},
                    {"name": "ì‹¬ë¦¬ ë¶„ì„", "description": "ì‹¬ë¦¬ìƒíƒœ ë¶„ì„ ëŒ€ê¸° ì¤‘", "completed": False, "current": False},
                    {"name": "ì„±ê²© ë¶„ë¥˜", "description": "í‚¤ì›Œë“œ ê¸°ë°˜ ì„±ê²©ìœ í˜• ë¶„ë¥˜ ëŒ€ê¸° ì¤‘", "completed": False, "current": False}
                ],
                "current_step": 1,
                "completed_steps": 0,
                "total_steps": 3,
                "estimated_remaining": "2-3ë¶„"
            })
        
        # DBì—ì„œ ì§ì ‘ í™•ë¥  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê¸°ì¡´ JSON íŒŒì¼ ì˜ì¡´ì„± ì œê±°)
        pipeline = get_pipeline()
        result_text = test_result.summary_text  # DBì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
        
        # ì„±ê²© ìœ í˜• ë§¤í•‘ (persona_type ID -> ì´ë¦„)
        personality_mapping = {
            1: "ì¶”ì§„í˜•",  # ì¶”ì§„ì´
            2: "ë‚´ë©´í˜•",  # ë‚´ë©´ì´  
            3: "ê´€ê³„í˜•",  # ê´€ê³„ì´
            4: "ì¾Œë½í˜•",  # ì¾Œë½ì´
            5: "ì•ˆì •í˜•"   # ì•ˆì •ì´
        }
        
        # DBì—ì„œ í™•ë¥  ë°ì´í„° ì¶”ì¶œ
        probabilities = {
            "ì¶”ì§„í˜•": float(test_result.dog_scores or 0.0),
            "ë‚´ë©´í˜•": float(test_result.cat_scores or 0.0),
            "ê´€ê³„í˜•": float(test_result.rabbit_scores or 0.0),
            "ì¾Œë½í˜•": float(test_result.bear_scores or 0.0),
            "ì•ˆì •í˜•": float(test_result.turtle_scores or 0.0)
        }
        
        # ìµœê³  í™•ë¥  ìœ í˜• ì°¾ê¸°
        if probabilities and any(v > 0 for v in probabilities.values()):
            predicted_personality = max(probabilities.items(), key=lambda x: x[1])[0]
            analysis_method = "keyword_classifier"
        else:
            # í™•ë¥  ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° persona_typeì—ì„œ ê°€ì ¸ì˜¤ê¸°
            predicted_personality = personality_mapping.get(test_result.persona_type, "ë‚´ë©´í˜•")
            analysis_method = "fallback"
        
        # í‚¤ì›Œë“œ ì •ë³´ (ê¸°ë³¸ê°’ ì œê³µ)
        keyword_info = {
            "current_keywords": [],
            "previous_keywords": [],  
            "total_keywords": 0,
            "confidence": max(probabilities.values()) / 100.0 if probabilities else 0.0
        }
        
        print(f"ğŸ“Š API ì‘ë‹µ ë°ì´í„° ì¤€ë¹„:")
        print(f"  - predicted_personality: {predicted_personality}")
        print(f"  - probabilities: {probabilities}")
        print(f"  - persona_type: {test_result.persona_type}")
        print(f"  - analysis_method: {analysis_method}")

        # ë¶„ì„ ì™„ë£Œ
        return JSONResponse(content={
            "test_id": test_id,
            "status": "completed",
            "message": "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "steps": [
                {"name": "ê°ì²´ íƒì§€", "description": "YOLOë¥¼ ì‚¬ìš©í•œ ê·¸ë¦¼ ìš”ì†Œ ê²€ì¶œ", "completed": True, "current": False},
                {"name": "ì‹¬ë¦¬ ë¶„ì„", "description": "GPT-4ë¥¼ ì‚¬ìš©í•œ ì‹¬ë¦¬ìƒíƒœ ë¶„ì„", "completed": True, "current": False},
                {"name": "ì„±ê²© ë¶„ë¥˜", "description": "í‚¤ì›Œë“œ ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•œ ì„±ê²©ìœ í˜• ë¶„ë¥˜", "completed": True, "current": False}
            ],
            "current_step": 3,
            "completed_steps": 3,
            "total_steps": 3,
            "result": {
                "persona_type": test_result.persona_type,
                "summary_text": test_result.summary_text,
                "result_text": result_text,
                "predicted_personality": predicted_personality,
                "probabilities": probabilities,
                "analysis_method": analysis_method,
                "keyword_analysis": keyword_info,
                "created_at": test_result.created_at.isoformat() if test_result.created_at else None,
                "image_url": drawing_test.image_url  # ì´ë¯¸ì§€ URL ì¶”ê°€
            }
        })
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ë¶„ì„ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get("/pipeline-health")
async def check_pipeline_health():
    """
    íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸ API
    
    ì‹œìŠ¤í…œ ê´€ë¦¬ìê°€ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œì˜ ìƒíƒœë¥¼ í™•ì¸í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Returns:
        JSON: íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì •ë³´
    """
    try:
        # ê¸°ë³¸ ìƒíƒœ ì •ë³´
        status = {
            "pipeline_status": "unknown",
            "timestamp": datetime.now().isoformat(),
            "components": {
                "pipeline_import": False,
                "yolo_model": False,
                "openai_api": False,
                "kobert_model": False,
                "directories": False
            },
            "directories": {},
            "error_details": None
        }
        
        # íŒŒì´í”„ë¼ì¸ import í™•ì¸
        if HTPAnalysisPipeline is not None:
            status["components"]["pipeline_import"] = True
            
            try:
                pipeline = get_pipeline()
                
                status["directories"] = {
                    "test_images": str(pipeline.config.test_img_dir),
                    "detection_results": str(pipeline.config.detection_results_dir),
                    "rag_docs": str(pipeline.config.rag_dir)
                }
                
                # YOLO ëª¨ë¸ í™•ì¸
                yolo_path = pipeline.config.model_dir / pipeline.config.yolo_model_path
                status["components"]["yolo_model"] = yolo_path.exists()
                
                # OpenAI API í‚¤ í™•ì¸
                status["components"]["openai_api"] = bool(os.getenv('OPENAI_API_KEY'))
                
                # KoBERT ëª¨ë¸ í™•ì¸
                kobert_path = pipeline.config.model_dir / pipeline.config.kobert_model_path
                status["components"]["kobert_model"] = kobert_path.exists()
                
                # ë””ë ‰í† ë¦¬ í™•ì¸
                required_dirs = [
                    pipeline.config.test_img_dir,
                    pipeline.config.detection_results_dir,
                    pipeline.config.rag_dir
                ]
                status["components"]["directories"] = all(d.exists() for d in required_dirs)
                
            except Exception as pipeline_error:
                status["error_details"] = f"Pipeline initialization failed: {str(pipeline_error)}"
        else:
            if PIPELINE_IMPORT_ERROR and "numpy.dtype size changed" in PIPELINE_IMPORT_ERROR:
                status["error_details"] = {
                    "message": "numpy/pandas ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ",
                    "error": PIPELINE_IMPORT_ERROR,
                    "solution": "conda install -c conda-forge numpy pandas --force-reinstall",
                    "alternative": "pip uninstall numpy pandas -y && pip install numpy pandas",
                    "help": "numpyì™€ pandasì˜ ë²„ì „ì´ í˜¸í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¬ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                }
            else:
                missing_packages = ["pandas", "transformers", "ultralytics", "torch", "opencv-python", "scikit-learn"]
                status["error_details"] = {
                    "message": "HTPAnalysisPipeline could not be imported",
                    "error": PIPELINE_IMPORT_ERROR or "Unknown import error",
                    "missing_packages": missing_packages,
                    "install_command": f"pip install {' '.join(missing_packages)}",
                    "help": "HTP ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ìœ„ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
                }
        
        # ì „ì²´ ìƒíƒœ íŒë‹¨
        if status["components"]["pipeline_import"]:
            all_healthy = all(status["components"].values())
            status["pipeline_status"] = "healthy" if all_healthy else "degraded"
        else:
            status["pipeline_status"] = "unavailable"
        
        return JSONResponse(content=status)
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "pipeline_status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "error_details": "Health check failed completely"
            }
        )
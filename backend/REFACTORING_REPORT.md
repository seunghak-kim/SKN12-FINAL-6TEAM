# 백엔드 리팩토링 작업 보고서

## 1. 개요
본 문서는 백엔드 코드의 품질, 유지보수성, 성능 향상을 위해 수행된 리팩토링 작업의 상세 내용을 기술합니다. 주요 목표는 하드코딩된 경로 제거, 서비스 계층 도입, 의존성 주입(DI) 적용, 그리고 AI 모델 로딩 최적화였습니다.

## 2. 주요 작업 내용

### 2.1 서비스 계층(Service Layer) 도입
- **파일**: `backend/app/services/analysis_service.py`
- **내용**: 
  - 비즈니스 로직을 API 엔드포인트에서 분리하여 `AnalysisService` 클래스로 캡슐화했습니다.
  - 이미지 분석, 결과 저장, 백그라운드 작업 실행 등의 핵심 로직을 서비스 계층에서 전담하도록 변경했습니다.
  - 싱글톤(Singleton) 패턴을 적용하여 서비스 인스턴스와 파이프라인 객체를 효율적으로 관리합니다.

### 2.2 API 리팩토링 및 의존성 주입(Dependency Injection)
- **파일**: `backend/app/api/pipeline.py`
- **내용**:
  - FastAPI의 `Depends`를 사용하여 `AnalysisService`를 API 엔드포인트에 주입받도록 구조를 변경했습니다.
  - 기존의 전역 변수 의존성을 제거하고, 테스트 용이성과 모듈성을 확보했습니다.
  - `/analyze-image`, `/analysis-status`, `/pipeline-health` 등의 주요 엔드포인트가 서비스 계층을 통해 동작하도록 수정했습니다.

### 2.3 YOLO 모델 최적화 (캐싱 적용)
- **파일**: `backend/llm/model/crop_by_labels.py`
- **내용**:
  - YOLO 모델을 매 요청마다 새로 로드하던 비효율적인 방식을 개선했습니다.
  - 전역 변수 `_YOLO_MODEL`을 활용한 캐싱 메커니즘을 도입하여, 최초 1회 로드 후 메모리에 상주한 모델을 재사용하도록 최적화했습니다.
  - 이를 통해 객체 탐지 단계의 지연 시간(Latency)을 대폭 감소시켰습니다.

### 2.4 LLM 프롬프트 엔지니어링 및 JSON 모드 적용
- **파일**: `backend/llm/model/analyze_images_with_gpt.py`
- **내용**:
  - GPT-4o API 호출 시 **JSON 모드**를 강제하여 응답의 일관성을 확보했습니다.
  - 프롬프트를 개선하여 심리 분석 결과가 구조화된 JSON 데이터로 반환되도록 했습니다.
  - 기존의 불안정한 텍스트 파싱 로직을 제거하고, `json.loads()`를 통해 안정적으로 데이터를 추출하도록 변경했습니다.
  - RAG(검색 증강 생성) 로직을 JSON 구조에 맞춰 재구성하여 분석의 정확도를 높였습니다.

## 3. 기대 효과
- **유지보수성 향상**: 비즈니스 로직과 API 처리 로직의 분리로 코드 이해 및 수정이 용이해졌습니다.
- **성능 개선**: 무거운 AI 모델(YOLO)의 중복 로딩을 방지하여 응답 속도가 빨라졌습니다.
- **안정성 확보**: LLM 응답을 정형화된 JSON으로 받아 처리함으로써 파싱 오류 가능성을 최소화했습니다.
- **확장성**: 의존성 주입 패턴 적용으로 향후 테스트 코드 작성이나 기능 확장이 수월해졌습니다.
